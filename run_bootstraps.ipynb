{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from poutyne import Model\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix\n",
    "from torchvision.datasets import ImageFolder\n",
    "from custom_lib.data_prep import data_transformation_pipeline, data_loader\n",
    "from custom_lib.eval_tools import bootstrap_evaluation_poutyne, tb_metrics_generator\n",
    "import importlib\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Bootstrap Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"~/Documents/data/\"\n",
    "external_data_folder = \"mendeley_expanded_tb\"\n",
    "tb_class_index = 1\n",
    "model_folder = \"tb_results\"\n",
    "n_bootstraps = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name, **kwargs):\n",
    "    \"\"\"Dynamically loads and instantiates a model from custom_lib.custom_models.\"\"\"\n",
    "    module = importlib.import_module(f\"custom_lib.custom_models.{model_name}\")\n",
    "    \n",
    "    # Find the first class in the module (assuming only one model class per file)\n",
    "    model_class = getattr(module, model_name, None)\n",
    "    \n",
    "    if model_class is None:\n",
    "        raise ValueError(f\"Could not find a class named '{model_name}' in '{module.__name__}'\")\n",
    "\n",
    "    return model_class(**kwargs)\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_evaluation_poutyne(model, data, save_logs, n_bootstraps, seed, tb_class_index, results_dir=None):\n",
    "    \"\"\"\n",
    "    Perform bootstrap evaluation of a model on a test dataset.\n",
    "\n",
    "    Args:\n",
    "        model: The trained Poutyne model to evaluate.\n",
    "        data: The dataset to evaluate on (e.g., ImageFolder dataset).\n",
    "        save_logs: Whether to save the metric distributions to CSV.\n",
    "        n_bootstraps: Number of bootstrap samples to generate.\n",
    "        seed: Random seed for reproducibility.\n",
    "        results_dir: Directory to save the bootstrap distribution CSV.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame with mean and confidence intervals for:\n",
    "        - Accuracy\n",
    "        - F1 Score\n",
    "        - Sensitivity (Recall)\n",
    "        - Specificity\n",
    "        - Test Loss\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "\n",
    "    # Store bootstrapped metrics\n",
    "    metrics = {\n",
    "        \"accuracy\": [],\n",
    "        \"f1_score\": [],\n",
    "        \"sensitivity\": [],\n",
    "        \"specificity\": [],\n",
    "        \"loss\": [],\n",
    "    }\n",
    "\n",
    "    # Calculate 10% of the dataset size\n",
    "    # subset_size = int(0.1 * len(data))\n",
    "\n",
    "    for i in range(n_bootstraps):\n",
    "        print(f\"step {i + 1}/{n_bootstraps}\")\n",
    "        # Sample 10% of the data with replacement\n",
    "        sampled_indices = rng.choice(len(data), len(data), replace=True)\n",
    "        sampled_subset = Subset(data, sampled_indices)\n",
    "        sampled_loader = DataLoader(sampled_subset, batch_size=32 * 2, shuffle=False)\n",
    "\n",
    "        # Evaluate the model on the sampled subset\n",
    "        sample_test_loss, sample_test_acc, sample_y_pred, sample_y_true = model.evaluate_generator(\n",
    "            sampled_loader, \n",
    "            return_pred=True,\n",
    "            return_ground_truth=True\n",
    "        )\n",
    "\n",
    "        sample_sens, sample_spec = tb_metrics_generator(y_pred=sample_y_pred, y_true=sample_y_true, tb_class_index=tb_class_index)\n",
    "        sample_f1_score = 2 * (sample_sens * sample_spec) / (sample_spec + sample_sens)\n",
    "\n",
    "        # Append metrics to the list\n",
    "        metrics[\"accuracy\"].append(sample_test_acc)\n",
    "        metrics[\"loss\"].append(sample_test_loss)\n",
    "        metrics[\"sensitivity\"].append(sample_sens)\n",
    "        metrics[\"specificity\"].append(sample_spec)\n",
    "        metrics[\"f1_score\"].append(sample_f1_score)\n",
    "\n",
    "    # Convert metrics to a DataFrame\n",
    "    metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "    if save_logs:\n",
    "        metrics_df.to_csv(f\"{results_dir}/bootstrap_distribution.csv\", index=False)\n",
    "\n",
    "    # Calculate mean and confidence intervals\n",
    "    mean_metrics = metrics_df.mean()\n",
    "    confidence_intervals = metrics_df.apply(lambda x: np.percentile(x, [2.5, 97.5]))\n",
    "\n",
    "    # Create a wide DataFrame for mean and confidence intervals\n",
    "    results_df = pd.DataFrame()\n",
    "\n",
    "    # Add mean, lower_ci, and upper_ci for each metric\n",
    "    for metric in mean_metrics.index:\n",
    "        results_df[f\"{metric}_mean\"] = [mean_metrics[metric]]\n",
    "        results_df[f\"{metric}_lower_ci\"] = [confidence_intervals[metric][0]]  # 2.5th percentile\n",
    "        results_df[f\"{metric}_upper_ci\"] = [confidence_intervals[metric][1]]  # 97.5th percentile\n",
    "\n",
    "    if save_logs:\n",
    "        results_df.to_csv(f\"{results_dir}/metrics_df.csv\", index=False)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "        \"cuda\"\n",
    "        if torch.cuda.is_available()\n",
    "        else \"mps\"\n",
    "        if torch.backends.mps.is_available()\n",
    "        else \"cpu\"\n",
    "        )\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "model = load_model(\n",
    "        \"truncated_b0\",\n",
    "        num_classes=2,\n",
    "        removed_layers=0,\n",
    "        batch_size=32,\n",
    "        image_size=224,\n",
    "        pretrained=True,\n",
    "        dropout_p=.2\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create val transform\n",
    "val_transform = data_transformation_pipeline(image_size = 224,\n",
    "                                            center_crop=224, \n",
    "                                            normalize=True,\n",
    "                                            is_train=False)\n",
    "\n",
    "external_data_path = f\"{data_dir}/{external_data_folder}\"\n",
    "\n",
    "# Apply transformations to dataset\n",
    "external_data = ImageFolder(external_data_path, transform=val_transform)\n",
    "\n",
    "external_test_loader = DataLoader(\n",
    "                external_data, batch_size=32 * 2, num_workers=4, pin_memory=True, drop_last=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subdirs = [\"truncated_b0_reduced_layers_5_2025-03-07_18-23\", \"truncated_b0_reduced_layers_4_2025-03-07_17-50\", \"truncated_b0_reduced_layers_0_2025-03-10_13-48\"]\n",
    "\n",
    "# bootstrap_results = pd.DataFrame()\n",
    "\n",
    "# for subdir in subdirs:\n",
    "#     results_path = f\"external_bootstrap_results1k/{subdir}\"\n",
    "\n",
    "#     # Regular expression to extract the number after \"_layers_\"\n",
    "#     match = re.search(r'_layers_(\\d+)', subdir)\n",
    "#     removed_layers = int(match.group(1))\n",
    "\n",
    "#     # Create the directory, ensuring parent directories exist\n",
    "#     os.makedirs(results_path, exist_ok=True)\n",
    "\n",
    "#     model = load_model(\n",
    "#                 \"truncated_b0\",\n",
    "#                 num_classes=2,\n",
    "#                 removed_layers=removed_layers,\n",
    "#                 batch_size=32,\n",
    "#                 image_size=224,\n",
    "#                 pretrained=True,\n",
    "#                 dropout_p=.2\n",
    "#                         )\n",
    "\n",
    "\n",
    "#     poutyne_model = Model(\n",
    "#                         model,\n",
    "#                         optimizer=torch.optim.Adam(model.parameters(), lr=.001),\n",
    "#                         loss_function=nn.CrossEntropyLoss(),\n",
    "#                         batch_metrics=[\"accuracy\"],\n",
    "#                         device=device\n",
    "#                         )\n",
    "    \n",
    "#     poutyne_model.network.load_state_dict(torch.load(f\"{model_folder}/{subdir}/best_model.pth\"))\n",
    "\n",
    "    \n",
    "#     new_rows = bootstrap_evaluation_poutyne(model=poutyne_model, seed=42, \n",
    "#                              data=external_data,\n",
    "#                              save_logs=True, \n",
    "#                              n_bootstraps=n_bootstraps,\n",
    "#                              tb_class_index=tb_class_index,\n",
    "#                              results_dir=results_path)\n",
    "\n",
    "#     new_rows['model_name'] = subdir\n",
    "\n",
    "#     new_rows['trunc_blocks'] = removed_layers\n",
    "\n",
    "#     bootstrap_results = pd.concat([bootstrap_results, new_rows])\n",
    "\n",
    "\n",
    "# bootstrap_results.to_csv(f\"external_bootstrap_results1k/bootstrap_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gw/q9_8w8jn0js6k5m5d98vhhcdzkx593/T/ipykernel_7683/4255415085.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  poutyne_model.network.load_state_dict(torch.load(f\"tb_results_new/truncated_b0_act1_reduced_layers_3_2025-03-16_13-28/best_model.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.makedirs('external_bootstrap_results1k_new/truncated_b0_act1_reduced_layers_3_2025-03-16_13-28', exist_ok=True)\n",
    "\n",
    "\n",
    "model = load_model(\n",
    "                \"truncated_b0_act1\",\n",
    "                num_classes=2,\n",
    "                removed_layers=3,\n",
    "                batch_size=32,\n",
    "                image_size=224,\n",
    "                pretrained=True,\n",
    "                dropout_p=.2\n",
    "                        )\n",
    "\n",
    "\n",
    "poutyne_model = Model(\n",
    "                    model,\n",
    "                    optimizer=torch.optim.Adam(model.parameters(), lr=.001),\n",
    "                    loss_function=nn.CrossEntropyLoss(),\n",
    "                    batch_metrics=[\"accuracy\"],\n",
    "                    device=device\n",
    "                    )\n",
    "    \n",
    "poutyne_model.network.load_state_dict(torch.load(f\"tb_results_new/truncated_b0_act1_reduced_layers_3_2025-03-16_13-28/best_model.pth\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1/1000\n",
      "Test steps: 76 10.92s test_loss: 0.084357 test_acc: 97.006237                                 \n",
      "step 2/1000\n",
      "Test steps: 76 10.24s test_loss: 0.074349 test_acc: 97.463617                                \n",
      "step 3/1000\n",
      "Test steps: 76 10.22s test_loss: 0.074839 test_acc: 97.151767                                \n",
      "step 4/1000\n",
      "Test steps: 76 10.37s test_loss: 0.071837 test_acc: 97.463617                                \n",
      "step 5/1000\n",
      "Test steps: 76 10.42s test_loss: 0.089625 test_acc: 96.923077                                \n",
      "step 6/1000\n",
      "Test steps: 76 10.28s test_loss: 0.079257 test_acc: 97.027027                                \n",
      "step 7/1000\n",
      "Test steps: 76 10.23s test_loss: 0.065345 test_acc: 97.588358                                \n",
      "step 8/1000\n",
      "Test steps: 76 10.20s test_loss: 0.069853 test_acc: 97.484407                                 \n",
      "step 9/1000\n",
      "Test steps: 76 10.30s test_loss: 0.065735 test_acc: 97.879418                                \n",
      "step 10/1000\n",
      "Test steps: 76 10.46s test_loss: 0.080860 test_acc: 97.068607                                \n",
      "step 11/1000\n",
      "Test steps: 76 10.31s test_loss: 0.079191 test_acc: 97.151767                                 \n",
      "step 12/1000\n",
      "Test steps: 76 10.26s test_loss: 0.074156 test_acc: 97.110187                                 \n",
      "step 13/1000\n",
      "Test steps: 76 10.33s test_loss: 0.076202 test_acc: 97.214137                                 \n",
      "step 14/1000\n",
      "Test steps: 76 10.24s test_loss: 0.079009 test_acc: 97.338877                                \n",
      "step 15/1000\n",
      "Test steps: 76 10.19s test_loss: 0.061918 test_acc: 97.713098                                \n",
      "step 16/1000\n",
      "Test steps: 76 10.48s test_loss: 0.075625 test_acc: 97.297297                                 \n",
      "step 17/1000\n",
      "Test steps: 76 10.17s test_loss: 0.069373 test_acc: 97.214137                                \n",
      "step 18/1000\n",
      "Test steps: 76 10.24s test_loss: 0.082843 test_acc: 97.110187                                \n",
      "step 19/1000\n",
      "Test steps: 76 10.24s test_loss: 0.076873 test_acc: 97.130977                                 \n",
      "step 20/1000\n",
      "Test steps: 76 10.24s test_loss: 0.069233 test_acc: 97.422037                                \n",
      "step 21/1000\n",
      "Test steps: 76 10.27s test_loss: 0.076287 test_acc: 97.422037                                 \n",
      "step 22/1000\n",
      "Test steps: 76 10.33s test_loss: 0.069543 test_acc: 97.276507                                 \n",
      "step 23/1000\n",
      "Test steps: 76 10.24s test_loss: 0.066778 test_acc: 97.692308                                \n",
      "step 24/1000\n",
      "Test steps: 76 10.21s test_loss: 0.074652 test_acc: 97.255717                                \n",
      "step 25/1000\n",
      "Test steps: 76 10.28s test_loss: 0.076976 test_acc: 96.964657                                \n",
      "step 26/1000\n",
      "Test steps: 76 10.26s test_loss: 0.078290 test_acc: 97.047817                                 \n",
      "step 27/1000\n",
      "Test steps: 76 10.29s test_loss: 0.079828 test_acc: 97.276507                                 \n",
      "step 28/1000\n",
      "Test steps: 76 10.38s test_loss: 0.066566 test_acc: 97.609148                                \n",
      "step 29/1000\n",
      "Test steps: 76 10.25s test_loss: 0.071480 test_acc: 97.276507                                 \n",
      "step 30/1000\n",
      "Test steps: 76 10.31s test_loss: 0.064244 test_acc: 97.713098                                \n",
      "step 31/1000\n",
      "Test steps: 76 10.36s test_loss: 0.067314 test_acc: 97.650728                                \n",
      "step 32/1000\n",
      "Test steps: 76 10.23s test_loss: 0.070713 test_acc: 97.671518                                \n",
      "step 33/1000\n",
      "Test steps: 76 10.28s test_loss: 0.066141 test_acc: 97.442827                                 \n",
      "step 34/1000\n",
      "Test steps: 76 10.43s test_loss: 0.078093 test_acc: 97.027027                                \n",
      "step 35/1000\n",
      "Test steps: 76 10.29s test_loss: 0.068764 test_acc: 97.318087                                \n",
      "step 36/1000\n",
      "Test steps: 76 10.34s test_loss: 0.080206 test_acc: 97.089397                                 \n",
      "step 37/1000\n",
      "Test steps: 76 10.36s test_loss: 0.064343 test_acc: 97.567568                                 \n",
      "step 38/1000\n",
      "Test steps: 76 10.33s test_loss: 0.070411 test_acc: 97.546778                                \n",
      "step 39/1000\n",
      "Test steps: 76 10.33s test_loss: 0.077139 test_acc: 97.068607                                \n",
      "step 40/1000\n",
      "Test steps: 76 10.39s test_loss: 0.075176 test_acc: 97.359667                                 \n",
      "step 41/1000\n",
      "Test steps: 76 10.28s test_loss: 0.074580 test_acc: 97.318087                                \n",
      "step 42/1000\n",
      "Test steps: 76 10.40s test_loss: 0.074488 test_acc: 97.151767                                 \n",
      "step 43/1000\n",
      "Test steps: 76 10.31s test_loss: 0.077958 test_acc: 97.172557                                \n",
      "step 44/1000\n",
      "Test steps: 76 10.33s test_loss: 0.064412 test_acc: 97.713098                                 \n",
      "step 45/1000\n",
      "Test steps: 76 10.47s test_loss: 0.073341 test_acc: 97.380457                                 \n",
      "step 46/1000\n",
      "Test steps: 76 10.32s test_loss: 0.064291 test_acc: 97.692308                                \n",
      "step 47/1000\n",
      "Test steps: 76 10.33s test_loss: 0.058205 test_acc: 97.692308                                 \n",
      "step 48/1000\n",
      "Test steps: 76 10.35s test_loss: 0.074811 test_acc: 97.193347                                \n",
      "step 49/1000\n",
      "Test steps: 76 10.33s test_loss: 0.070844 test_acc: 97.463617                                 \n",
      "step 50/1000\n",
      "Test steps: 76 10.37s test_loss: 0.071908 test_acc: 97.505198                                 \n",
      "step 51/1000\n",
      "Test steps: 76 10.34s test_loss: 0.078824 test_acc: 97.089397                                \n",
      "step 52/1000\n",
      "Test steps: 76 10.37s test_loss: 0.073716 test_acc: 97.525988                                \n",
      "step 53/1000\n",
      "Test steps: 76 10.49s test_loss: 0.065826 test_acc: 97.567568                                 \n",
      "step 54/1000\n",
      "Test steps: 76 10.50s test_loss: 0.086173 test_acc: 96.819127                                 \n",
      "step 55/1000\n",
      "Test steps: 76 10.36s test_loss: 0.076138 test_acc: 97.359667                                 \n",
      "step 56/1000\n",
      "Test steps: 76 10.36s test_loss: 0.077628 test_acc: 96.985447                                 \n",
      "step 57/1000\n",
      "Test steps: 76 10.39s test_loss: 0.087481 test_acc: 97.027027                                \n",
      "step 58/1000\n",
      "Test steps: 76 10.37s test_loss: 0.080374 test_acc: 97.172557                                \n",
      "step 59/1000\n",
      "Test steps: 76 10.32s test_loss: 0.067803 test_acc: 97.588358                                \n",
      "step 60/1000\n",
      "Test steps: 76 10.42s test_loss: 0.068984 test_acc: 97.546778                                 \n",
      "step 61/1000\n",
      "Test steps: 76 10.36s test_loss: 0.065986 test_acc: 97.505198                                \n",
      "step 62/1000\n",
      "Test steps: 76 10.41s test_loss: 0.066561 test_acc: 97.484407                                \n",
      "step 63/1000\n",
      "Test steps: 76 10.40s test_loss: 0.070023 test_acc: 97.567568                                \n",
      "step 64/1000\n",
      "Test steps: 76 10.32s test_loss: 0.079524 test_acc: 97.006237                                 \n",
      "step 65/1000\n",
      "Test steps: 76 10.38s test_loss: 0.079832 test_acc: 96.943867                                 \n",
      "step 66/1000\n",
      "Test steps: 76 10.43s test_loss: 0.060922 test_acc: 97.650728                                \n",
      "step 67/1000\n",
      "Test steps: 76 10.33s test_loss: 0.068914 test_acc: 97.463617                                 \n",
      "step 68/1000\n",
      "Test steps: 76 10.35s test_loss: 0.071812 test_acc: 97.151767                                \n",
      "step 69/1000\n",
      "Test steps: 76 10.40s test_loss: 0.075965 test_acc: 97.193347                                 \n",
      "step 70/1000\n",
      "Test steps: 76 10.43s test_loss: 0.068965 test_acc: 97.692308                                 \n",
      "step 71/1000\n",
      "Test steps: 76 10.45s test_loss: 0.074733 test_acc: 97.422037                                \n",
      "step 72/1000\n",
      "Test steps: 76 10.39s test_loss: 0.067120 test_acc: 97.567568                                 \n",
      "step 73/1000\n",
      "Test steps: 76 10.32s test_loss: 0.073049 test_acc: 97.151767                                 \n",
      "step 74/1000\n",
      "Test steps: 76 10.42s test_loss: 0.075864 test_acc: 97.401247                                 \n",
      "step 75/1000\n",
      "Test steps: 76 10.28s test_loss: 0.078202 test_acc: 97.130977                                 \n",
      "step 76/1000\n",
      "Test steps: 76 10.42s test_loss: 0.070712 test_acc: 97.276507                                 \n",
      "step 77/1000\n",
      "Test steps: 76 10.48s test_loss: 0.075295 test_acc: 97.214137                                 \n",
      "step 78/1000\n",
      "Test steps: 76 10.39s test_loss: 0.067934 test_acc: 97.463617                                \n",
      "step 79/1000\n",
      "Test steps: 76 10.49s test_loss: 0.067704 test_acc: 97.505198                                \n",
      "step 80/1000\n",
      "Test steps: 76 10.53s test_loss: 0.073896 test_acc: 97.359667                                \n",
      "step 81/1000\n",
      "Test steps: 76 10.28s test_loss: 0.072907 test_acc: 97.297297                                 \n",
      "step 82/1000\n",
      "Test steps: 76 10.79s test_loss: 0.079835 test_acc: 97.130977                                \n",
      "step 83/1000\n",
      "Test steps: 76 10.60s test_loss: 0.075660 test_acc: 97.234927                                \n",
      "step 84/1000\n",
      "Test steps: 76 10.30s test_loss: 0.070467 test_acc: 97.255717                                \n",
      "step 85/1000\n",
      "Test steps: 76 10.49s test_loss: 0.070287 test_acc: 97.422037                                 \n",
      "step 86/1000\n",
      "Test steps: 76 10.44s test_loss: 0.077359 test_acc: 97.234927                                \n",
      "step 87/1000\n",
      "Test steps: 76 10.54s test_loss: 0.076455 test_acc: 97.234927                                \n",
      "step 88/1000\n",
      "Test steps: 76 10.48s test_loss: 0.078491 test_acc: 97.089397                                \n",
      "step 89/1000\n",
      "Test steps: 76 10.56s test_loss: 0.062608 test_acc: 97.567568                                \n",
      "step 90/1000\n",
      "Test steps: 76 10.51s test_loss: 0.066693 test_acc: 97.671518                                 \n",
      "step 91/1000\n",
      "Test steps: 76 10.45s test_loss: 0.077436 test_acc: 97.359667                                 \n",
      "step 92/1000\n",
      "Test steps: 76 10.59s test_loss: 0.064827 test_acc: 97.567568                                 \n",
      "step 93/1000\n",
      "Test steps: 76 10.64s test_loss: 0.063130 test_acc: 97.754678                                \n",
      "step 94/1000\n",
      "Test steps: 76 10.58s test_loss: 0.064480 test_acc: 97.629938                                \n",
      "step 95/1000\n",
      "Test steps: 76 10.51s test_loss: 0.072549 test_acc: 97.359667                                 \n",
      "step 96/1000\n",
      "Test steps: 76 10.41s test_loss: 0.082047 test_acc: 97.151767                                \n",
      "step 97/1000\n",
      "Test steps: 76 10.54s test_loss: 0.074740 test_acc: 97.214137                                 \n",
      "step 98/1000\n",
      "Test steps: 76 10.57s test_loss: 0.073099 test_acc: 97.380457                                \n",
      "step 99/1000\n",
      "Test steps: 76 10.38s test_loss: 0.065342 test_acc: 97.567568                                 \n",
      "step 100/1000\n",
      "Test steps: 76 10.59s test_loss: 0.074538 test_acc: 97.193347                                 \n",
      "step 101/1000\n",
      "Test steps: 76 10.41s test_loss: 0.075121 test_acc: 97.359667                                \n",
      "step 102/1000\n",
      "Test steps: 76 10.49s test_loss: 0.069824 test_acc: 97.338877                                 \n",
      "step 103/1000\n",
      "Test steps: 76 10.63s test_loss: 0.069023 test_acc: 97.380457                                 \n",
      "step 104/1000\n",
      "Test steps: 76 10.60s test_loss: 0.065894 test_acc: 97.484407                                 \n",
      "step 105/1000\n",
      "Test steps: 76 10.46s test_loss: 0.067105 test_acc: 97.733888                                \n",
      "step 106/1000\n",
      "Test steps: 76 10.58s test_loss: 0.069469 test_acc: 97.234927                                 \n",
      "step 107/1000\n",
      "Test steps: 76 10.48s test_loss: 0.071122 test_acc: 97.068607                                \n",
      "step 108/1000\n",
      "Test steps: 76 10.54s test_loss: 0.070627 test_acc: 97.484407                                \n",
      "step 109/1000\n",
      "Test steps: 76 10.44s test_loss: 0.076514 test_acc: 97.214137                                \n",
      "step 110/1000\n",
      "Test steps: 76 10.56s test_loss: 0.065829 test_acc: 97.650728                                 \n",
      "step 111/1000\n",
      "Test steps: 76 10.42s test_loss: 0.062753 test_acc: 97.837838                                 \n",
      "step 112/1000\n",
      "Test steps: 76 10.49s test_loss: 0.081612 test_acc: 97.151767                                 \n",
      "step 113/1000\n",
      "Test steps: 76 10.45s test_loss: 0.066021 test_acc: 97.318087                                \n",
      "step 114/1000\n",
      "Test steps: 76 10.60s test_loss: 0.073302 test_acc: 97.588358                                \n",
      "step 115/1000\n",
      "Test steps: 76 10.46s test_loss: 0.071074 test_acc: 97.338877                                \n",
      "step 116/1000\n",
      "Test steps: 76 10.44s test_loss: 0.074180 test_acc: 97.151767                                 \n",
      "step 117/1000\n",
      "Test steps: 76 10.61s test_loss: 0.078725 test_acc: 97.151767                                \n",
      "step 118/1000\n",
      "Test steps: 76 10.51s test_loss: 0.068362 test_acc: 97.525988                                 \n",
      "step 119/1000\n",
      "Test steps: 76 10.56s test_loss: 0.065579 test_acc: 97.775468                                 \n",
      "step 120/1000\n",
      "Test steps: 76 10.58s test_loss: 0.070883 test_acc: 97.671518                                 \n",
      "step 121/1000\n",
      "Test steps: 76 10.41s test_loss: 0.076138 test_acc: 97.297297                                 \n",
      "step 122/1000\n",
      "Test steps: 76 10.43s test_loss: 0.067531 test_acc: 97.297297                                \n",
      "step 123/1000\n",
      "Test steps: 76 10.46s test_loss: 0.080363 test_acc: 96.881497                                \n",
      "step 124/1000\n",
      "Test steps: 76 10.50s test_loss: 0.066406 test_acc: 97.505198                                 \n",
      "step 125/1000\n",
      "Test steps: 76 10.50s test_loss: 0.076425 test_acc: 97.359667                                \n",
      "step 126/1000\n",
      "Test steps: 76 10.59s test_loss: 0.071023 test_acc: 97.338877                                \n",
      "step 127/1000\n",
      "Test steps: 76 10.59s test_loss: 0.077598 test_acc: 97.151767                                 \n",
      "step 128/1000\n",
      "Test steps: 76 10.59s test_loss: 0.069329 test_acc: 97.442827                                \n",
      "step 129/1000\n",
      "Test steps: 76 10.53s test_loss: 0.081899 test_acc: 97.047817                                 \n",
      "step 130/1000\n",
      "Test steps: 76 10.55s test_loss: 0.076565 test_acc: 97.297297                                \n",
      "step 131/1000\n",
      "Test steps: 76 10.57s test_loss: 0.069887 test_acc: 97.380457                                \n",
      "step 132/1000\n",
      "Test steps: 76 10.64s test_loss: 0.065905 test_acc: 97.629938                                \n",
      "step 133/1000\n",
      "Test steps: 76 10.48s test_loss: 0.060932 test_acc: 97.567568                                \n",
      "step 134/1000\n",
      "Test steps: 76 10.56s test_loss: 0.072825 test_acc: 97.505198                                \n",
      "step 135/1000\n",
      "Test steps: 76 10.53s test_loss: 0.074282 test_acc: 97.359667                                \n",
      "step 136/1000\n",
      "Test steps: 76 10.44s test_loss: 0.064444 test_acc: 97.941788                                 \n",
      "step 137/1000\n",
      "Test steps: 76 10.69s test_loss: 0.082659 test_acc: 97.068607                                \n",
      "step 138/1000\n",
      "Test steps: 76 10.52s test_loss: 0.070744 test_acc: 97.629938                                 \n",
      "step 139/1000\n",
      "Test steps: 76 10.42s test_loss: 0.075942 test_acc: 97.276507                                \n",
      "step 140/1000\n",
      "Test steps: 76 10.57s test_loss: 0.075060 test_acc: 97.338877                                 \n",
      "step 141/1000\n",
      "Test steps: 76 10.46s test_loss: 0.081257 test_acc: 97.338877                                \n",
      "step 142/1000\n",
      "Test steps: 76 10.51s test_loss: 0.067252 test_acc: 97.546778                                 \n",
      "step 143/1000\n",
      "Test steps: 76 10.57s test_loss: 0.076748 test_acc: 97.338877                                \n",
      "step 144/1000\n",
      "Test steps: 76 10.55s test_loss: 0.071934 test_acc: 97.484407                                 \n",
      "step 145/1000\n",
      "Test steps: 76 10.37s test_loss: 0.079682 test_acc: 97.047817                                \n",
      "step 146/1000\n",
      "Test steps: 76 10.54s test_loss: 0.079297 test_acc: 97.151767                                 \n",
      "step 147/1000\n",
      "Test steps: 76 10.49s test_loss: 0.075540 test_acc: 97.338877                                 \n",
      "step 148/1000\n",
      "Test steps: 76 10.38s test_loss: 0.076858 test_acc: 97.338877                                 \n",
      "step 149/1000\n",
      "Test steps: 76 10.60s test_loss: 0.074762 test_acc: 97.338877                                 \n",
      "step 150/1000\n",
      "Test steps: 76 10.53s test_loss: 0.068966 test_acc: 97.422037                                \n",
      "step 151/1000\n",
      "Test steps: 76 10.51s test_loss: 0.074114 test_acc: 97.422037                                 \n",
      "step 152/1000\n",
      "Test steps: 76 10.56s test_loss: 0.081114 test_acc: 97.255717                                 \n",
      "step 153/1000\n",
      "Test steps: 76 10.48s test_loss: 0.078606 test_acc: 97.089397                                 \n",
      "step 154/1000\n",
      "Test steps: 76 10.59s test_loss: 0.067409 test_acc: 97.505198                                 \n",
      "step 155/1000\n",
      "Test steps: 76 10.65s test_loss: 0.073748 test_acc: 97.546778                                 \n",
      "step 156/1000\n",
      "Test steps: 76 10.66s test_loss: 0.071242 test_acc: 97.401247                                 \n",
      "step 157/1000\n",
      "Test steps: 76 10.59s test_loss: 0.070797 test_acc: 97.359667                                 \n",
      "step 158/1000\n",
      "Test steps: 76 10.56s test_loss: 0.068803 test_acc: 97.463617                                 \n",
      "step 159/1000\n",
      "Test steps: 76 10.54s test_loss: 0.078440 test_acc: 97.338877                                \n",
      "step 160/1000\n",
      "Test steps: 76 10.55s test_loss: 0.069691 test_acc: 97.525988                                 \n",
      "step 161/1000\n",
      "Test steps: 76 10.60s test_loss: 0.070764 test_acc: 97.318087                                 \n",
      "step 162/1000\n",
      "Test steps: 76 10.63s test_loss: 0.055906 test_acc: 97.900208                                 \n",
      "step 163/1000\n",
      "Test steps: 76 10.51s test_loss: 0.070547 test_acc: 97.629938                                 \n",
      "step 164/1000\n",
      "Test steps: 76 10.56s test_loss: 0.055952 test_acc: 97.692308                                 \n",
      "step 165/1000\n",
      "Test steps: 76 10.61s test_loss: 0.073395 test_acc: 97.359667                                \n",
      "step 166/1000\n",
      "Test steps: 76 10.60s test_loss: 0.065641 test_acc: 97.650728                                 \n",
      "step 167/1000\n",
      "Test steps: 76 10.59s test_loss: 0.073883 test_acc: 97.609148                                 \n",
      "step 168/1000\n",
      "Test steps: 76 10.65s test_loss: 0.059880 test_acc: 97.609148                                 \n",
      "step 169/1000\n",
      "Test steps: 76 10.60s test_loss: 0.069624 test_acc: 97.359667                                \n",
      "step 170/1000\n",
      "Test steps: 76 10.60s test_loss: 0.068873 test_acc: 97.546778                                 \n",
      "step 171/1000\n",
      "Test steps: 76 10.52s test_loss: 0.070077 test_acc: 97.359667                                 \n",
      "step 172/1000\n",
      "Test steps: 76 10.63s test_loss: 0.061420 test_acc: 97.546778                                \n",
      "step 173/1000\n",
      "Test steps: 76 10.51s test_loss: 0.060161 test_acc: 97.609148                                \n",
      "step 174/1000\n",
      "Test steps: 76 10.48s test_loss: 0.080585 test_acc: 97.006237                                \n",
      "step 175/1000\n",
      "Test steps: 76 10.38s test_loss: 0.071767 test_acc: 97.255717                                 \n",
      "step 176/1000\n",
      "Test steps: 76 10.56s test_loss: 0.073600 test_acc: 97.401247                                \n",
      "step 177/1000\n",
      "Test steps: 76 10.60s test_loss: 0.075662 test_acc: 97.193347                                 \n",
      "step 178/1000\n",
      "Test steps: 76 10.61s test_loss: 0.071020 test_acc: 97.546778                                 \n",
      "step 179/1000\n",
      "Test steps: 76 10.50s test_loss: 0.073224 test_acc: 97.214137                                \n",
      "step 180/1000\n",
      "Test steps: 76 10.49s test_loss: 0.069780 test_acc: 97.588358                                \n",
      "step 181/1000\n",
      "Test steps: 76 10.54s test_loss: 0.069471 test_acc: 97.713098                                 \n",
      "step 182/1000\n",
      "Test steps: 76 10.48s test_loss: 0.080943 test_acc: 97.047817                                \n",
      "step 183/1000\n",
      "Test steps: 76 10.57s test_loss: 0.066489 test_acc: 97.629938                                 \n",
      "step 184/1000\n",
      "Test steps: 76 10.63s test_loss: 0.071455 test_acc: 97.234927                                \n",
      "step 185/1000\n",
      "Test steps: 76 10.55s test_loss: 0.076757 test_acc: 97.172557                                 \n",
      "step 186/1000\n",
      "Test steps: 76 10.43s test_loss: 0.065956 test_acc: 97.401247                                \n",
      "step 187/1000\n",
      "Test steps: 76 10.49s test_loss: 0.071290 test_acc: 97.193347                                 \n",
      "step 188/1000\n",
      "Test steps: 76 10.51s test_loss: 0.066515 test_acc: 97.525988                                \n",
      "step 189/1000\n",
      "Test steps: 76 10.65s test_loss: 0.077540 test_acc: 97.234927                                 \n",
      "step 190/1000\n",
      "Test steps: 76 10.45s test_loss: 0.080608 test_acc: 97.214137                                \n",
      "step 191/1000\n",
      "Test steps: 76 10.57s test_loss: 0.068734 test_acc: 97.151767                                \n",
      "step 192/1000\n",
      "Test steps: 76 10.59s test_loss: 0.071853 test_acc: 97.234927                                 \n",
      "step 193/1000\n",
      "Test steps: 76 10.92s test_loss: 0.085695 test_acc: 96.860707                                 \n",
      "step 194/1000\n",
      "Test steps: 76 10.67s test_loss: 0.071434 test_acc: 97.318087                                \n",
      "step 195/1000\n",
      "Test steps: 76 10.53s test_loss: 0.069196 test_acc: 97.463617                                 \n",
      "step 196/1000\n",
      "Test steps: 76 10.51s test_loss: 0.065990 test_acc: 97.775468                                 \n",
      "step 197/1000\n",
      "Test steps: 76 10.50s test_loss: 0.075842 test_acc: 97.276507                                \n",
      "step 198/1000\n",
      "Test steps: 76 10.55s test_loss: 0.074141 test_acc: 97.463617                                 \n",
      "step 199/1000\n",
      "Test steps: 76 10.56s test_loss: 0.073473 test_acc: 97.255717                                \n",
      "step 200/1000\n",
      "Test steps: 76 10.47s test_loss: 0.070384 test_acc: 97.567568                                 \n",
      "step 201/1000\n",
      "Test steps: 76 10.55s test_loss: 0.087431 test_acc: 96.943867                                \n",
      "step 202/1000\n",
      "Test steps: 76 10.52s test_loss: 0.073841 test_acc: 97.172557                                 \n",
      "step 203/1000\n",
      "Test steps: 76 10.49s test_loss: 0.066571 test_acc: 97.422037                                 \n",
      "step 204/1000\n",
      "Test steps: 76 10.31s test_loss: 0.070430 test_acc: 97.609148                                \n",
      "step 205/1000\n",
      "Test steps: 76 10.59s test_loss: 0.074384 test_acc: 97.234927                                \n",
      "step 206/1000\n",
      "Test steps: 76 10.49s test_loss: 0.073626 test_acc: 97.172557                                 \n",
      "step 207/1000\n",
      "Test steps: 76 10.53s test_loss: 0.068981 test_acc: 97.629938                                 \n",
      "step 208/1000\n",
      "Test steps: 76 10.53s test_loss: 0.065390 test_acc: 97.422037                                 \n",
      "step 209/1000\n",
      "Test steps: 76 10.53s test_loss: 0.069108 test_acc: 97.713098                                 \n",
      "step 210/1000\n",
      "Test steps: 76 10.49s test_loss: 0.071637 test_acc: 97.380457                                \n",
      "step 211/1000\n",
      "Test steps: 76 10.44s test_loss: 0.086026 test_acc: 97.006237                                 \n",
      "step 212/1000\n",
      "Test steps: 76 10.43s test_loss: 0.066587 test_acc: 97.650728                                 \n",
      "step 213/1000\n",
      "Test steps: 76 10.41s test_loss: 0.075738 test_acc: 97.318087                                 \n",
      "step 214/1000\n",
      "Test steps: 76 10.49s test_loss: 0.073621 test_acc: 97.401247                                \n",
      "step 215/1000\n",
      "Test steps: 76 10.44s test_loss: 0.079440 test_acc: 97.172557                                \n",
      "step 216/1000\n",
      "Test steps: 76 10.37s test_loss: 0.070459 test_acc: 97.650728                                 \n",
      "step 217/1000\n",
      "Test steps: 76 10.66s test_loss: 0.068205 test_acc: 97.401247                                 \n",
      "step 218/1000\n",
      "Test steps: 76 10.55s test_loss: 0.084051 test_acc: 97.068607                                 \n",
      "step 219/1000\n",
      "Test steps: 76 10.54s test_loss: 0.071510 test_acc: 97.567568                                \n",
      "step 220/1000\n",
      "Test steps: 76 10.48s test_loss: 0.065137 test_acc: 97.463617                                \n",
      "step 221/1000\n",
      "Test steps: 76 10.47s test_loss: 0.072796 test_acc: 97.380457                                \n",
      "step 222/1000\n",
      "Test steps: 76 10.62s test_loss: 0.076495 test_acc: 97.338877                                 \n",
      "step 223/1000\n",
      "Test steps: 76 10.64s test_loss: 0.077579 test_acc: 97.359667                                 \n",
      "step 224/1000\n",
      "Test steps: 76 10.61s test_loss: 0.080688 test_acc: 97.214137                                 \n",
      "step 225/1000\n",
      "Test steps: 76 10.59s test_loss: 0.066485 test_acc: 97.546778                                \n",
      "step 226/1000\n",
      "Test steps: 76 10.52s test_loss: 0.070470 test_acc: 97.525988                                \n",
      "step 227/1000\n",
      "Test steps: 76 10.59s test_loss: 0.079459 test_acc: 97.047817                                \n",
      "step 228/1000\n",
      "Test steps: 76 10.60s test_loss: 0.069802 test_acc: 97.338877                                 \n",
      "step 229/1000\n",
      "Test steps: 76 10.65s test_loss: 0.075536 test_acc: 97.276507                                 \n",
      "step 230/1000\n",
      "Test steps: 76 10.51s test_loss: 0.081754 test_acc: 97.047817                                \n",
      "step 231/1000\n",
      "Test steps: 76 10.55s test_loss: 0.064985 test_acc: 97.733888                                 \n",
      "step 232/1000\n",
      "Test steps: 76 10.54s test_loss: 0.066958 test_acc: 97.505198                                 \n",
      "step 233/1000\n",
      "Test steps: 76 10.48s test_loss: 0.072014 test_acc: 97.401247                                \n",
      "step 234/1000\n",
      "Test steps: 76 10.66s test_loss: 0.068809 test_acc: 97.567568                                 \n",
      "step 235/1000\n",
      "Test steps: 76 10.43s test_loss: 0.063630 test_acc: 97.817048                                \n",
      "step 236/1000\n",
      "Test steps: 76 10.47s test_loss: 0.082464 test_acc: 97.047817                                 \n",
      "step 237/1000\n",
      "Test steps: 76 10.60s test_loss: 0.076011 test_acc: 97.338877                                 \n",
      "step 238/1000\n",
      "Test steps: 76 10.46s test_loss: 0.076772 test_acc: 97.214137                                \n",
      "step 239/1000\n",
      "Test steps: 76 10.54s test_loss: 0.076421 test_acc: 97.318087                                 \n",
      "step 240/1000\n",
      "Test steps: 76 10.52s test_loss: 0.079018 test_acc: 97.089397                                \n",
      "step 241/1000\n",
      "Test steps: 76 10.81s test_loss: 0.065044 test_acc: 97.629938                                 \n",
      "step 242/1000\n",
      "Test steps: 76 10.60s test_loss: 0.076015 test_acc: 97.193347                                 \n",
      "step 243/1000\n",
      "Test steps: 76 10.57s test_loss: 0.075386 test_acc: 97.234927                                \n",
      "step 244/1000\n",
      "Test steps: 76 10.52s test_loss: 0.074964 test_acc: 97.359667                                 \n",
      "step 245/1000\n",
      "Test steps: 76 10.54s test_loss: 0.061484 test_acc: 97.442827                                 \n",
      "step 246/1000\n",
      "Test steps: 76 10.54s test_loss: 0.078421 test_acc: 97.151767                                \n",
      "step 247/1000\n",
      "Test steps: 76 10.58s test_loss: 0.062763 test_acc: 97.733888                                \n",
      "step 248/1000\n",
      "Test steps: 76 10.62s test_loss: 0.071572 test_acc: 97.359667                                \n",
      "step 249/1000\n",
      "Test steps: 76 10.48s test_loss: 0.078756 test_acc: 97.234927                                 \n",
      "step 250/1000\n",
      "Test steps: 76 10.50s test_loss: 0.075650 test_acc: 97.401247                                \n",
      "step 251/1000\n",
      "Test steps: 76 10.70s test_loss: 0.072266 test_acc: 97.505198                                \n",
      "step 252/1000\n",
      "Test steps: 76 10.53s test_loss: 0.067641 test_acc: 97.484407                                 \n",
      "step 253/1000\n",
      "Test steps: 76 10.55s test_loss: 0.064981 test_acc: 97.692308                                \n",
      "step 254/1000\n",
      "Test steps: 76 10.53s test_loss: 0.080146 test_acc: 97.214137                                 \n",
      "step 255/1000\n",
      "Test steps: 76 10.53s test_loss: 0.076493 test_acc: 97.006237                                 \n",
      "step 256/1000\n",
      "Test steps: 76 10.59s test_loss: 0.072796 test_acc: 97.193347                                \n",
      "step 257/1000\n",
      "Test steps: 76 10.58s test_loss: 0.068665 test_acc: 97.692308                                \n",
      "step 258/1000\n",
      "Test steps: 76 10.68s test_loss: 0.075794 test_acc: 97.089397                                 \n",
      "step 259/1000\n",
      "Test steps: 76 10.68s test_loss: 0.070823 test_acc: 97.505198                                 \n",
      "step 260/1000\n",
      "Test steps: 76 10.59s test_loss: 0.075993 test_acc: 97.401247                                \n",
      "step 261/1000\n",
      "Test steps: 76 10.61s test_loss: 0.067764 test_acc: 97.525988                                 \n",
      "step 262/1000\n",
      "Test steps: 76 10.67s test_loss: 0.063783 test_acc: 97.713098                                 \n",
      "step 263/1000\n",
      "Test steps: 76 10.56s test_loss: 0.073083 test_acc: 97.276507                                \n",
      "step 264/1000\n",
      "Test steps: 76 10.49s test_loss: 0.071880 test_acc: 97.359667                                 \n",
      "step 265/1000\n",
      "Test steps: 76 10.52s test_loss: 0.078612 test_acc: 97.297297                                 \n",
      "step 266/1000\n",
      "Test steps: 76 10.62s test_loss: 0.078812 test_acc: 97.027027                                 \n",
      "step 267/1000\n",
      "Test steps: 76 10.62s test_loss: 0.075476 test_acc: 97.380457                                \n",
      "step 268/1000\n",
      "Test steps: 76 10.68s test_loss: 0.067589 test_acc: 97.629938                                 \n",
      "step 269/1000\n",
      "Test steps: 76 10.68s test_loss: 0.064817 test_acc: 97.567568                                 \n",
      "step 270/1000\n",
      "Test steps: 76 10.54s test_loss: 0.076868 test_acc: 97.151767                                \n",
      "step 271/1000\n",
      "Test steps: 76 10.61s test_loss: 0.080104 test_acc: 97.297297                                \n",
      "step 272/1000\n",
      "Test steps: 76 10.54s test_loss: 0.061715 test_acc: 97.796258                                 \n",
      "step 273/1000\n",
      "Test steps: 76 10.53s test_loss: 0.076547 test_acc: 97.255717                                \n",
      "step 274/1000\n",
      "Test steps: 76 10.70s test_loss: 0.068491 test_acc: 97.671518                                 \n",
      "step 275/1000\n",
      "Test steps: 76 10.70s test_loss: 0.079039 test_acc: 96.964657                                \n",
      "step 276/1000\n",
      "Test steps: 76 10.55s test_loss: 0.069387 test_acc: 97.463617                                 \n",
      "step 277/1000\n",
      "Test steps: 76 10.45s test_loss: 0.073793 test_acc: 97.110187                                 \n",
      "step 278/1000\n",
      "Test steps: 76 10.62s test_loss: 0.081813 test_acc: 96.839917                                \n",
      "step 279/1000\n",
      "Test steps: 76 10.67s test_loss: 0.060942 test_acc: 97.754678                                \n",
      "step 280/1000\n",
      "Test steps: 76 10.58s test_loss: 0.068839 test_acc: 97.359667                                 \n",
      "step 281/1000\n",
      "Test steps: 76 10.57s test_loss: 0.072953 test_acc: 97.380457                                 \n",
      "step 282/1000\n",
      "Test steps: 76 10.59s test_loss: 0.065035 test_acc: 97.817048                                 \n",
      "step 283/1000\n",
      "Test steps: 76 10.49s test_loss: 0.071460 test_acc: 97.276507                                \n",
      "step 284/1000\n",
      "Test steps: 76 10.46s test_loss: 0.066151 test_acc: 97.629938                                 \n",
      "step 285/1000\n",
      "Test steps: 76 10.50s test_loss: 0.079180 test_acc: 97.214137                                 \n",
      "step 286/1000\n",
      "Test steps: 76 10.57s test_loss: 0.066548 test_acc: 97.442827                                \n",
      "step 287/1000\n",
      "Test steps: 76 10.67s test_loss: 0.060563 test_acc: 97.650728                                 \n",
      "step 288/1000\n",
      "Test steps: 76 10.62s test_loss: 0.079220 test_acc: 97.318087                                 \n",
      "step 289/1000\n",
      "Test steps: 76 10.55s test_loss: 0.066268 test_acc: 97.650728                                 \n",
      "step 290/1000\n",
      "Test steps: 76 10.89s test_loss: 0.075454 test_acc: 97.110187                                \n",
      "step 291/1000\n",
      "Test steps: 76 10.56s test_loss: 0.073725 test_acc: 97.401247                                 \n",
      "step 292/1000\n",
      "Test steps: 76 10.52s test_loss: 0.064389 test_acc: 97.588358                                 \n",
      "step 293/1000\n",
      "Test steps: 76 10.78s test_loss: 0.078651 test_acc: 97.193347                                 \n",
      "step 294/1000\n",
      "Test steps: 76 10.65s test_loss: 0.067739 test_acc: 97.463617                                 \n",
      "step 295/1000\n",
      "Test steps: 76 10.62s test_loss: 0.069549 test_acc: 97.837838                                 \n",
      "step 296/1000\n",
      "Test steps: 76 10.72s test_loss: 0.060203 test_acc: 97.713098                                 \n",
      "step 297/1000\n",
      "Test steps: 76 10.67s test_loss: 0.072637 test_acc: 97.359667                                \n",
      "step 298/1000\n",
      "Test steps: 76 10.64s test_loss: 0.068132 test_acc: 97.442827                                 \n",
      "step 299/1000\n",
      "Test steps: 76 10.66s test_loss: 0.075116 test_acc: 97.484407                                \n",
      "step 300/1000\n",
      "Test steps: 76 10.77s test_loss: 0.072131 test_acc: 97.442827                                 \n",
      "step 301/1000\n",
      "Test steps: 76 10.69s test_loss: 0.082354 test_acc: 96.985447                                 \n",
      "step 302/1000\n",
      "Test steps: 76 10.57s test_loss: 0.071282 test_acc: 97.359667                                 \n",
      "step 303/1000\n",
      "Test steps: 76 10.64s test_loss: 0.074837 test_acc: 97.255717                                 \n",
      "step 304/1000\n",
      "Test steps: 76 10.67s test_loss: 0.051824 test_acc: 98.087318                                 \n",
      "step 305/1000\n",
      "Test steps: 76 10.68s test_loss: 0.075771 test_acc: 97.422037                                 \n",
      "step 306/1000\n",
      "Test steps: 76 10.66s test_loss: 0.068554 test_acc: 97.442827                                 \n",
      "step 307/1000\n",
      "Test steps: 76 10.78s test_loss: 0.069464 test_acc: 97.359667                                \n",
      "step 308/1000\n",
      "Test steps: 76 10.77s test_loss: 0.069700 test_acc: 97.380457                                 \n",
      "step 309/1000\n",
      "Test steps: 76 11.09s test_loss: 0.068498 test_acc: 97.525988                                 \n",
      "step 310/1000\n",
      "Test steps: 76 10.69s test_loss: 0.076308 test_acc: 97.089397                                \n",
      "step 311/1000\n",
      "Test steps: 76 10.54s test_loss: 0.060455 test_acc: 97.817048                                 \n",
      "step 312/1000\n",
      "Test steps: 76 10.66s test_loss: 0.074815 test_acc: 97.172557                                \n",
      "step 313/1000\n",
      "Test steps: 76 10.71s test_loss: 0.065946 test_acc: 97.609148                                 \n",
      "step 314/1000\n",
      "Test steps: 76 10.68s test_loss: 0.066163 test_acc: 97.463617                                 \n",
      "step 315/1000\n",
      "Test steps: 76 10.55s test_loss: 0.058319 test_acc: 97.941788                                \n",
      "step 316/1000\n",
      "Test steps: 76 10.65s test_loss: 0.061466 test_acc: 97.629938                                 \n",
      "step 317/1000\n",
      "Test steps: 76 10.58s test_loss: 0.076752 test_acc: 97.297297                                 \n",
      "step 318/1000\n",
      "Test steps: 76 10.59s test_loss: 0.070571 test_acc: 97.234927                                 \n",
      "step 319/1000\n",
      "Test steps: 76 10.70s test_loss: 0.073280 test_acc: 97.214137                                 \n",
      "step 320/1000\n",
      "Test steps: 76 10.61s test_loss: 0.073991 test_acc: 97.130977                                 \n",
      "step 321/1000\n",
      "Test steps: 76 10.71s test_loss: 0.074703 test_acc: 97.234927                                 \n",
      "step 322/1000\n",
      "Test steps: 76 10.74s test_loss: 0.058928 test_acc: 97.650728                                 \n",
      "step 323/1000\n",
      "Test steps: 76 10.54s test_loss: 0.068350 test_acc: 97.380457                                 \n",
      "step 324/1000\n",
      "Test steps: 76 10.68s test_loss: 0.063660 test_acc: 97.505198                                \n",
      "step 325/1000\n",
      "Test steps: 76 10.70s test_loss: 0.077273 test_acc: 97.151767                                \n",
      "step 326/1000\n",
      "Test steps: 76 10.69s test_loss: 0.085591 test_acc: 96.839917                                \n",
      "step 327/1000\n",
      "Test steps: 76 10.62s test_loss: 0.081630 test_acc: 96.798337                                 \n",
      "step 328/1000\n",
      "Test steps: 76 10.74s test_loss: 0.067877 test_acc: 97.484407                                \n",
      "step 329/1000\n",
      "Test steps: 76 10.80s test_loss: 0.077547 test_acc: 97.234927                                \n",
      "step 330/1000\n",
      "Test steps: 76 10.88s test_loss: 0.071260 test_acc: 97.525988                                 \n",
      "step 331/1000\n",
      "Test steps: 76 10.66s test_loss: 0.076117 test_acc: 97.110187                                \n",
      "step 332/1000\n",
      "Test steps: 76 10.55s test_loss: 0.064992 test_acc: 97.567568                                 \n",
      "step 333/1000\n",
      "Test steps: 76 10.64s test_loss: 0.075955 test_acc: 97.505198                                 \n",
      "step 334/1000\n",
      "Test steps: 76 10.67s test_loss: 0.077330 test_acc: 97.214137                                \n",
      "step 335/1000\n",
      "Test steps: 76 10.61s test_loss: 0.072476 test_acc: 97.297297                                 \n",
      "step 336/1000\n",
      "Test steps: 76 10.60s test_loss: 0.071395 test_acc: 97.525988                                 \n",
      "step 337/1000\n",
      "Test steps: 76 10.51s test_loss: 0.066869 test_acc: 97.422037                                \n",
      "step 338/1000\n",
      "Test steps: 76 10.66s test_loss: 0.062343 test_acc: 97.629938                                 \n",
      "step 339/1000\n",
      "Test steps: 76 10.67s test_loss: 0.071690 test_acc: 97.151767                                 \n",
      "step 340/1000\n",
      "Test steps: 76 10.69s test_loss: 0.083475 test_acc: 96.985447                                \n",
      "step 341/1000\n",
      "Test steps: 76 10.68s test_loss: 0.074451 test_acc: 97.380457                                 \n",
      "step 342/1000\n",
      "Test steps: 76 10.56s test_loss: 0.067214 test_acc: 97.588358                                 \n",
      "step 343/1000\n",
      "Test steps: 76 10.52s test_loss: 0.070406 test_acc: 97.463617                                \n",
      "step 344/1000\n",
      "Test steps: 76 10.58s test_loss: 0.063453 test_acc: 97.754678                                \n",
      "step 345/1000\n",
      "Test steps: 76 10.67s test_loss: 0.077215 test_acc: 97.214137                                \n",
      "step 346/1000\n",
      "Test steps: 76 10.64s test_loss: 0.065303 test_acc: 97.567568                                 \n",
      "step 347/1000\n",
      "Test steps: 76 10.75s test_loss: 0.061814 test_acc: 97.775468                                 \n",
      "step 348/1000\n",
      "Test steps: 76 10.65s test_loss: 0.075966 test_acc: 97.422037                                 \n",
      "step 349/1000\n",
      "Test steps: 76 10.77s test_loss: 0.066244 test_acc: 97.629938                                \n",
      "step 350/1000\n",
      "Test steps: 76 10.67s test_loss: 0.070604 test_acc: 97.609148                                \n",
      "step 351/1000\n",
      "Test steps: 76 10.74s test_loss: 0.067513 test_acc: 97.567568                                 \n",
      "step 352/1000\n",
      "Test steps: 76 10.66s test_loss: 0.080054 test_acc: 97.130977                                \n",
      "step 353/1000\n",
      "Test steps: 76 10.56s test_loss: 0.067347 test_acc: 97.525988                                 \n",
      "step 354/1000\n",
      "Test steps: 76 10.58s test_loss: 0.075851 test_acc: 97.255717                                 \n",
      "step 355/1000\n",
      "Test steps: 76 10.82s test_loss: 0.065239 test_acc: 97.629938                                 \n",
      "step 356/1000\n",
      "Test steps: 76 10.62s test_loss: 0.067596 test_acc: 97.629938                                \n",
      "step 357/1000\n",
      "Test steps: 76 10.69s test_loss: 0.078445 test_acc: 97.297297                                 \n",
      "step 358/1000\n",
      "Test steps: 76 11.02s test_loss: 0.069454 test_acc: 97.463617                                 \n",
      "step 359/1000\n",
      "Test steps: 76 10.60s test_loss: 0.058214 test_acc: 97.858628                                \n",
      "step 360/1000\n",
      "Test steps: 76 10.50s test_loss: 0.075016 test_acc: 97.380457                                \n",
      "step 361/1000\n",
      "Test steps: 76 10.62s test_loss: 0.071488 test_acc: 97.484407                                \n",
      "step 362/1000\n",
      "Test steps: 76 10.70s test_loss: 0.077155 test_acc: 97.172557                                \n",
      "step 363/1000\n",
      "Test steps: 76 10.58s test_loss: 0.077171 test_acc: 97.089397                                \n",
      "step 364/1000\n",
      "Test steps: 76 10.66s test_loss: 0.071513 test_acc: 97.110187                                \n",
      "step 365/1000\n",
      "Test steps: 76 10.65s test_loss: 0.076153 test_acc: 97.172557                                \n",
      "step 366/1000\n",
      "Test steps: 76 10.75s test_loss: 0.059551 test_acc: 97.920998                                \n",
      "step 367/1000\n",
      "Test steps: 76 10.66s test_loss: 0.074039 test_acc: 97.401247                                 \n",
      "step 368/1000\n",
      "Test steps: 76 10.61s test_loss: 0.078728 test_acc: 97.338877                                \n",
      "step 369/1000\n",
      "Test steps: 76 10.77s test_loss: 0.078096 test_acc: 97.255717                                \n",
      "step 370/1000\n",
      "Test steps: 76 10.64s test_loss: 0.069571 test_acc: 97.505198                                 \n",
      "step 371/1000\n",
      "Test steps: 76 10.55s test_loss: 0.067313 test_acc: 97.525988                                 \n",
      "step 372/1000\n",
      "Test steps: 76 10.63s test_loss: 0.071312 test_acc: 97.463617                                 \n",
      "step 373/1000\n",
      "Test steps: 76 10.61s test_loss: 0.073241 test_acc: 97.338877                                \n",
      "step 374/1000\n",
      "Test steps: 76 10.53s test_loss: 0.073552 test_acc: 97.359667                                 \n",
      "step 375/1000\n",
      "Test steps: 76 10.69s test_loss: 0.081300 test_acc: 97.255717                                 \n",
      "step 376/1000\n",
      "Test steps: 76 10.74s test_loss: 0.069896 test_acc: 97.900208                                \n",
      "step 377/1000\n",
      "Test steps: 76 10.75s test_loss: 0.077466 test_acc: 97.442827                                \n",
      "step 378/1000\n",
      "Test steps: 76 10.50s test_loss: 0.072930 test_acc: 97.463617                                 \n",
      "step 379/1000\n",
      "Test steps: 76 10.50s test_loss: 0.077520 test_acc: 97.276507                                \n",
      "step 380/1000\n",
      "Test steps: 76 10.57s test_loss: 0.071091 test_acc: 97.338877                                \n",
      "step 381/1000\n",
      "Test steps: 76 10.61s test_loss: 0.065616 test_acc: 97.422037                                 \n",
      "step 382/1000\n",
      "Test steps: 76 10.72s test_loss: 0.077821 test_acc: 97.359667                                 \n",
      "step 383/1000\n",
      "Test steps: 76 10.71s test_loss: 0.066011 test_acc: 97.567568                                 \n",
      "step 384/1000\n",
      "Test steps: 76 10.53s test_loss: 0.079127 test_acc: 97.089397                                \n",
      "step 385/1000\n",
      "Test steps: 76 10.65s test_loss: 0.076171 test_acc: 97.130977                                \n",
      "step 386/1000\n",
      "Test steps: 76 10.78s test_loss: 0.066098 test_acc: 97.796258                                 \n",
      "step 387/1000\n",
      "Test steps: 76 10.67s test_loss: 0.065670 test_acc: 97.422037                                 \n",
      "step 388/1000\n",
      "Test steps: 76 10.62s test_loss: 0.070574 test_acc: 97.422037                                 \n",
      "step 389/1000\n",
      "Test steps: 76 10.66s test_loss: 0.069859 test_acc: 97.442827                                 \n",
      "step 390/1000\n",
      "Test steps: 76 10.73s test_loss: 0.064548 test_acc: 97.671518                                 \n",
      "step 391/1000\n",
      "Test steps: 76 10.62s test_loss: 0.068775 test_acc: 97.525988                                \n",
      "step 392/1000\n",
      "Test steps: 76 10.81s test_loss: 0.075869 test_acc: 97.463617                                 \n",
      "step 393/1000\n",
      "Test steps: 76 10.65s test_loss: 0.079147 test_acc: 97.130977                                 \n",
      "step 394/1000\n",
      "Test steps: 76 10.63s test_loss: 0.075370 test_acc: 97.047817                                \n",
      "step 395/1000\n",
      "Test steps: 76 10.58s test_loss: 0.077817 test_acc: 97.422037                                \n",
      "step 396/1000\n",
      "Test steps: 76 10.53s test_loss: 0.085672 test_acc: 96.943867                                 \n",
      "step 397/1000\n",
      "Test steps: 76 10.77s test_loss: 0.066424 test_acc: 97.359667                                 \n",
      "step 398/1000\n",
      "Test steps: 76 10.64s test_loss: 0.076990 test_acc: 97.047817                                \n",
      "step 399/1000\n",
      "Test steps: 76 10.77s test_loss: 0.067397 test_acc: 97.588358                                \n",
      "step 400/1000\n",
      "Test steps: 76 10.63s test_loss: 0.069839 test_acc: 97.359667                                \n",
      "step 401/1000\n",
      "Test steps: 76 10.64s test_loss: 0.074414 test_acc: 97.276507                                \n",
      "step 402/1000\n",
      "Test steps: 76 10.60s test_loss: 0.072088 test_acc: 97.130977                                 \n",
      "step 403/1000\n",
      "Test steps: 76 10.73s test_loss: 0.069036 test_acc: 97.463617                                 \n",
      "step 404/1000\n",
      "Test steps: 76 10.64s test_loss: 0.073353 test_acc: 97.401247                                 \n",
      "step 405/1000\n",
      "Test steps: 76 10.68s test_loss: 0.080624 test_acc: 97.297297                                 \n",
      "step 406/1000\n",
      "Test steps: 76 10.74s test_loss: 0.083424 test_acc: 96.902287                                \n",
      "step 407/1000\n",
      "Test steps: 76 10.62s test_loss: 0.078573 test_acc: 97.068607                                 \n",
      "step 408/1000\n",
      "Test steps: 76 10.68s test_loss: 0.060096 test_acc: 97.775468                                 \n",
      "step 409/1000\n",
      "Test steps: 76 10.62s test_loss: 0.066857 test_acc: 97.276507                                \n",
      "step 410/1000\n",
      "Test steps: 76 10.73s test_loss: 0.070073 test_acc: 97.380457                                 \n",
      "step 411/1000\n",
      "Test steps: 76 10.70s test_loss: 0.071297 test_acc: 97.609148                                \n",
      "step 412/1000\n",
      "Test steps: 76 10.59s test_loss: 0.067127 test_acc: 97.380457                                \n",
      "step 413/1000\n",
      "Test steps: 76 10.67s test_loss: 0.064068 test_acc: 97.858628                                 \n",
      "step 414/1000\n",
      "Test steps: 76 10.81s test_loss: 0.070523 test_acc: 97.359667                                 \n",
      "step 415/1000\n",
      "Test steps: 76 10.69s test_loss: 0.072813 test_acc: 97.401247                                 \n",
      "step 416/1000\n",
      "Test steps: 76 10.64s test_loss: 0.069448 test_acc: 97.713098                                 \n",
      "step 417/1000\n",
      "Test steps: 76 10.69s test_loss: 0.072327 test_acc: 97.546778                                \n",
      "step 418/1000\n",
      "Test steps: 76 10.58s test_loss: 0.063495 test_acc: 97.546778                                 \n",
      "step 419/1000\n",
      "Test steps: 76 10.72s test_loss: 0.072953 test_acc: 97.380457                                \n",
      "step 420/1000\n",
      "Test steps: 76 10.70s test_loss: 0.066656 test_acc: 97.525988                                \n",
      "step 421/1000\n",
      "Test steps: 76 10.62s test_loss: 0.080813 test_acc: 97.318087                                 \n",
      "step 422/1000\n",
      "Test steps: 76 10.57s test_loss: 0.076505 test_acc: 97.068607                                \n",
      "step 423/1000\n",
      "Test steps: 76 10.66s test_loss: 0.073181 test_acc: 97.359667                                \n",
      "step 424/1000\n",
      "Test steps: 76 10.76s test_loss: 0.067656 test_acc: 97.588358                                 \n",
      "step 425/1000\n",
      "Test steps: 76 10.85s test_loss: 0.078326 test_acc: 97.172557                                \n",
      "step 426/1000\n",
      "Test steps: 76 10.69s test_loss: 0.070149 test_acc: 97.484407                                 \n",
      "step 427/1000\n",
      "Test steps: 76 10.59s test_loss: 0.072804 test_acc: 97.401247                                 \n",
      "step 428/1000\n",
      "Test steps: 76 10.64s test_loss: 0.081608 test_acc: 97.193347                                \n",
      "step 429/1000\n",
      "Test steps: 76 10.71s test_loss: 0.076527 test_acc: 97.130977                                \n",
      "step 430/1000\n",
      "Test steps: 76 10.73s test_loss: 0.076686 test_acc: 97.255717                                 \n",
      "step 431/1000\n",
      "Test steps: 76 10.67s test_loss: 0.069957 test_acc: 97.318087                                 \n",
      "step 432/1000\n",
      "Test steps: 76 10.68s test_loss: 0.071211 test_acc: 97.234927                                 \n",
      "step 433/1000\n",
      "Test steps: 76 10.64s test_loss: 0.087661 test_acc: 96.798337                                \n",
      "step 434/1000\n",
      "Test steps: 76 10.81s test_loss: 0.080449 test_acc: 97.214137                                \n",
      "step 435/1000\n",
      "Test steps: 76 10.54s test_loss: 0.068673 test_acc: 97.359667                                \n",
      "step 436/1000\n",
      "Test steps: 76 10.66s test_loss: 0.070022 test_acc: 97.609148                                 \n",
      "step 437/1000\n",
      "Test steps: 76 10.68s test_loss: 0.062254 test_acc: 97.754678                                 \n",
      "step 438/1000\n",
      "Test steps: 76 10.73s test_loss: 0.064689 test_acc: 97.546778                                \n",
      "step 439/1000\n",
      "Test steps: 76 10.71s test_loss: 0.079216 test_acc: 97.172557                                 \n",
      "step 440/1000\n",
      "Test steps: 76 10.51s test_loss: 0.067135 test_acc: 97.525988                                \n",
      "step 441/1000\n",
      "Test steps: 76 10.54s test_loss: 0.065624 test_acc: 97.567568                                 \n",
      "step 442/1000\n",
      "Test steps: 76 10.60s test_loss: 0.062033 test_acc: 97.879418                                 \n",
      "step 443/1000\n",
      "Test steps: 76 10.45s test_loss: 0.067772 test_acc: 97.629938                                 \n",
      "step 444/1000\n",
      "Test steps: 76 10.72s test_loss: 0.069556 test_acc: 97.276507                                 \n",
      "step 445/1000\n",
      "Test steps: 76 10.69s test_loss: 0.077933 test_acc: 97.234927                                 \n",
      "step 446/1000\n",
      "Test steps: 76 10.63s test_loss: 0.070416 test_acc: 97.422037                                 \n",
      "step 447/1000\n",
      "Test steps: 76 10.65s test_loss: 0.060161 test_acc: 97.733888                                 \n",
      "step 448/1000\n",
      "Test steps: 76 10.60s test_loss: 0.068929 test_acc: 97.546778                                \n",
      "step 449/1000\n",
      "Test steps: 76 10.60s test_loss: 0.069429 test_acc: 97.588358                                \n",
      "step 450/1000\n",
      "Test steps: 76 10.63s test_loss: 0.059361 test_acc: 97.713098                                 \n",
      "step 451/1000\n",
      "Test steps: 76 10.59s test_loss: 0.073226 test_acc: 97.359667                                 \n",
      "step 452/1000\n",
      "Test steps: 76 10.56s test_loss: 0.067807 test_acc: 97.546778                                 \n",
      "step 453/1000\n",
      "Test steps: 76 10.56s test_loss: 0.064114 test_acc: 97.609148                                 \n",
      "step 454/1000\n",
      "Test steps: 76 10.71s test_loss: 0.072850 test_acc: 97.588358                                 \n",
      "step 455/1000\n",
      "Test steps: 76 10.67s test_loss: 0.086562 test_acc: 96.964657                                 \n",
      "step 456/1000\n",
      "Test steps: 76 10.60s test_loss: 0.058729 test_acc: 97.900208                                 \n",
      "step 457/1000\n",
      "Test steps: 76 10.62s test_loss: 0.059341 test_acc: 97.920998                                 \n",
      "step 458/1000\n",
      "Test steps: 76 10.55s test_loss: 0.070194 test_acc: 97.401247                                 \n",
      "step 459/1000\n",
      "Test steps: 76 10.73s test_loss: 0.065437 test_acc: 97.359667                                 \n",
      "step 460/1000\n",
      "Test steps: 76 10.69s test_loss: 0.066835 test_acc: 97.463617                                 \n",
      "step 461/1000\n",
      "Test steps: 76 10.60s test_loss: 0.067823 test_acc: 97.525988                                 \n",
      "step 462/1000\n",
      "Test steps: 76 10.78s test_loss: 0.069427 test_acc: 97.629938                                 \n",
      "step 463/1000\n",
      "Test steps: 76 10.61s test_loss: 0.077542 test_acc: 97.110187                                \n",
      "step 464/1000\n",
      "Test steps: 76 10.57s test_loss: 0.077990 test_acc: 97.297297                                \n",
      "step 465/1000\n",
      "Test steps: 76 10.73s test_loss: 0.078948 test_acc: 97.130977                                 \n",
      "step 466/1000\n",
      "Test steps: 76 10.74s test_loss: 0.069947 test_acc: 97.650728                                \n",
      "step 467/1000\n",
      "Test steps: 76 10.62s test_loss: 0.086071 test_acc: 97.255717                                \n",
      "step 468/1000\n",
      "Test steps: 76 10.70s test_loss: 0.081845 test_acc: 97.318087                                 \n",
      "step 469/1000\n",
      "Test steps: 76 10.74s test_loss: 0.071322 test_acc: 97.338877                                 \n",
      "step 470/1000\n",
      "Test steps: 76 10.65s test_loss: 0.075886 test_acc: 97.359667                                \n",
      "step 471/1000\n",
      "Test steps: 76 10.68s test_loss: 0.071563 test_acc: 97.359667                                 \n",
      "step 472/1000\n",
      "Test steps: 76 10.55s test_loss: 0.075407 test_acc: 97.546778                                \n",
      "step 473/1000\n",
      "Test steps: 76 10.67s test_loss: 0.068651 test_acc: 97.422037                                 \n",
      "step 474/1000\n",
      "Test steps: 76 10.68s test_loss: 0.062861 test_acc: 97.546778                                 \n",
      "step 475/1000\n",
      "Test steps: 76 10.60s test_loss: 0.070715 test_acc: 97.463617                                \n",
      "step 476/1000\n",
      "Test steps: 76 10.67s test_loss: 0.071503 test_acc: 97.380457                                 \n",
      "step 477/1000\n",
      "Test steps: 76 10.56s test_loss: 0.069394 test_acc: 97.359667                                 \n",
      "step 478/1000\n",
      "Test steps: 76 10.64s test_loss: 0.076521 test_acc: 97.255717                                 \n",
      "step 479/1000\n",
      "Test steps: 76 10.69s test_loss: 0.067895 test_acc: 97.650728                                 \n",
      "step 480/1000\n",
      "Test steps: 76 10.61s test_loss: 0.061233 test_acc: 97.567568                                 \n",
      "step 481/1000\n",
      "Test steps: 76 10.68s test_loss: 0.062263 test_acc: 97.733888                                 \n",
      "step 482/1000\n",
      "Test steps: 76 10.76s test_loss: 0.065957 test_acc: 97.588358                                \n",
      "step 483/1000\n",
      "Test steps: 76 10.70s test_loss: 0.076720 test_acc: 97.089397                                 \n",
      "step 484/1000\n",
      "Test steps: 76 10.65s test_loss: 0.067354 test_acc: 97.733888                                \n",
      "step 485/1000\n",
      "Test steps: 76 10.63s test_loss: 0.065525 test_acc: 97.650728                                 \n",
      "step 486/1000\n",
      "Test steps: 76 10.52s test_loss: 0.064877 test_acc: 97.484407                                \n",
      "step 487/1000\n",
      "Test steps: 76 10.69s test_loss: 0.070163 test_acc: 97.858628                                 \n",
      "step 488/1000\n",
      "Test steps: 76 10.54s test_loss: 0.069936 test_acc: 97.442827                                 \n",
      "step 489/1000\n",
      "Test steps: 76 10.71s test_loss: 0.064664 test_acc: 97.567568                                 \n",
      "step 490/1000\n",
      "Test steps: 76 10.66s test_loss: 0.065356 test_acc: 97.484407                                 \n",
      "step 491/1000\n",
      "Test steps: 76 10.69s test_loss: 0.067957 test_acc: 97.359667                                 \n",
      "step 492/1000\n",
      "Test steps: 76 10.62s test_loss: 0.071242 test_acc: 97.442827                                 \n",
      "step 493/1000\n",
      "Test steps: 76 10.72s test_loss: 0.082102 test_acc: 96.923077                                 \n",
      "step 494/1000\n",
      "Test steps: 76 10.82s test_loss: 0.071578 test_acc: 97.546778                                 \n",
      "step 495/1000\n",
      "Test steps: 76 10.65s test_loss: 0.072614 test_acc: 97.463617                                 \n",
      "step 496/1000\n",
      "Test steps: 76 10.71s test_loss: 0.074508 test_acc: 97.484407                                \n",
      "step 497/1000\n",
      "Test steps: 76 10.70s test_loss: 0.080157 test_acc: 97.130977                                 \n",
      "step 498/1000\n",
      "Test steps: 76 10.58s test_loss: 0.076991 test_acc: 97.110187                                 \n",
      "step 499/1000\n",
      "Test steps: 76 10.71s test_loss: 0.067902 test_acc: 97.567568                                 \n",
      "step 500/1000\n",
      "Test steps: 76 10.69s test_loss: 0.065962 test_acc: 97.525988                                \n",
      "step 501/1000\n",
      "Test steps: 76 10.63s test_loss: 0.077101 test_acc: 97.380457                                \n",
      "step 502/1000\n",
      "Test steps: 76 10.59s test_loss: 0.072085 test_acc: 97.297297                                \n",
      "step 503/1000\n",
      "Test steps: 76 10.64s test_loss: 0.080458 test_acc: 97.151767                                 \n",
      "step 504/1000\n",
      "Test steps: 76 10.76s test_loss: 0.070255 test_acc: 97.525988                                \n",
      "step 505/1000\n",
      "Test steps: 76 10.65s test_loss: 0.075547 test_acc: 97.193347                                 \n",
      "step 506/1000\n",
      "Test steps: 76 10.67s test_loss: 0.072130 test_acc: 97.525988                                 \n",
      "step 507/1000\n",
      "Test steps: 76 10.65s test_loss: 0.072869 test_acc: 97.318087                                 \n",
      "step 508/1000\n",
      "Test steps: 76 10.74s test_loss: 0.081386 test_acc: 96.902287                                 \n",
      "step 509/1000\n",
      "Test steps: 76 10.78s test_loss: 0.071991 test_acc: 97.151767                                \n",
      "step 510/1000\n",
      "Test steps: 76 10.64s test_loss: 0.068258 test_acc: 97.338877                                 \n",
      "step 511/1000\n",
      "Test steps: 76 10.65s test_loss: 0.072333 test_acc: 97.318087                                \n",
      "step 512/1000\n",
      "Test steps: 76 10.64s test_loss: 0.070056 test_acc: 97.422037                                \n",
      "step 513/1000\n",
      "Test steps: 76 10.70s test_loss: 0.079413 test_acc: 97.130977                                \n",
      "step 514/1000\n",
      "Test steps: 76 10.54s test_loss: 0.074542 test_acc: 97.380457                                \n",
      "step 515/1000\n",
      "Test steps: 76 10.65s test_loss: 0.065475 test_acc: 97.567568                                 \n",
      "step 516/1000\n",
      "Test steps: 76 10.78s test_loss: 0.078035 test_acc: 97.318087                                \n",
      "step 517/1000\n",
      "Test steps: 76 10.68s test_loss: 0.066325 test_acc: 97.463617                                \n",
      "step 518/1000\n",
      "Test steps: 76 10.68s test_loss: 0.073427 test_acc: 97.505198                                \n",
      "step 519/1000\n",
      "Test steps: 76 10.59s test_loss: 0.069566 test_acc: 97.401247                                 \n",
      "step 520/1000\n",
      "Test steps: 76 10.46s test_loss: 0.067082 test_acc: 97.505198                                \n",
      "step 521/1000\n",
      "Test steps: 76 10.82s test_loss: 0.075025 test_acc: 97.359667                                 \n",
      "step 522/1000\n",
      "Test steps: 76 10.69s test_loss: 0.080425 test_acc: 97.276507                                 \n",
      "step 523/1000\n",
      "Test steps: 76 10.58s test_loss: 0.064001 test_acc: 97.837838                                \n",
      "step 524/1000\n",
      "Test steps: 76 10.69s test_loss: 0.066812 test_acc: 97.609148                                 \n",
      "step 525/1000\n",
      "Test steps: 76 10.63s test_loss: 0.064758 test_acc: 97.692308                                 \n",
      "step 526/1000\n",
      "Test steps: 76 10.58s test_loss: 0.076467 test_acc: 97.338877                                \n",
      "step 527/1000\n",
      "Test steps: 76 10.66s test_loss: 0.063309 test_acc: 97.817048                                 \n",
      "step 528/1000\n",
      "Test steps: 76 10.73s test_loss: 0.069621 test_acc: 97.463617                                 \n",
      "step 529/1000\n",
      "Test steps: 76 10.69s test_loss: 0.065343 test_acc: 97.733888                                 \n",
      "step 530/1000\n",
      "Test steps: 76 10.65s test_loss: 0.070768 test_acc: 97.214137                                 \n",
      "step 531/1000\n",
      "Test steps: 76 10.62s test_loss: 0.084693 test_acc: 96.985447                                 \n",
      "step 532/1000\n",
      "Test steps: 76 10.74s test_loss: 0.079202 test_acc: 97.234927                                \n",
      "step 533/1000\n",
      "Test steps: 76 10.66s test_loss: 0.075344 test_acc: 97.297297                                \n",
      "step 534/1000\n",
      "Test steps: 76 10.55s test_loss: 0.067544 test_acc: 97.297297                                 \n",
      "step 535/1000\n",
      "Test steps: 76 10.68s test_loss: 0.070055 test_acc: 97.276507                                \n",
      "step 536/1000\n",
      "Test steps: 76 10.67s test_loss: 0.075665 test_acc: 97.422037                                 \n",
      "step 537/1000\n",
      "Test steps: 76 10.57s test_loss: 0.060738 test_acc: 97.671518                                \n",
      "step 538/1000\n",
      "Test steps: 76 10.86s test_loss: 0.064938 test_acc: 97.463617                                 \n",
      "step 539/1000\n",
      "Test steps: 76 10.72s test_loss: 0.070111 test_acc: 97.359667                                 \n",
      "step 540/1000\n",
      "Test steps: 76 10.66s test_loss: 0.071429 test_acc: 97.380457                                 \n",
      "step 541/1000\n",
      "Test steps: 76 10.68s test_loss: 0.070574 test_acc: 97.172557                                 \n",
      "step 542/1000\n",
      "Test steps: 76 10.71s test_loss: 0.072242 test_acc: 97.255717                                 \n",
      "step 543/1000\n",
      "Test steps: 76 10.68s test_loss: 0.073115 test_acc: 97.193347                                \n",
      "step 544/1000\n",
      "Test steps: 76 10.75s test_loss: 0.076171 test_acc: 97.297297                                 \n",
      "step 545/1000\n",
      "Test steps: 76 10.72s test_loss: 0.069263 test_acc: 97.401247                                 \n",
      "step 546/1000\n",
      "Test steps: 76 10.69s test_loss: 0.065511 test_acc: 97.588358                                 \n",
      "step 547/1000\n",
      "Test steps: 76 10.74s test_loss: 0.072160 test_acc: 97.380457                                \n",
      "step 548/1000\n",
      "Test steps: 76 10.58s test_loss: 0.071233 test_acc: 97.463617                                \n",
      "step 549/1000\n",
      "Test steps: 76 10.68s test_loss: 0.068934 test_acc: 97.380457                                 \n",
      "step 550/1000\n",
      "Test steps: 76 10.73s test_loss: 0.063774 test_acc: 97.401247                                 \n",
      "step 551/1000\n",
      "Test steps: 76 10.65s test_loss: 0.066598 test_acc: 97.754678                                \n",
      "step 552/1000\n",
      "Test steps: 76 10.83s test_loss: 0.076600 test_acc: 97.172557                                \n",
      "step 553/1000\n",
      "Test steps: 76 10.74s test_loss: 0.073636 test_acc: 97.234927                                 \n",
      "step 554/1000\n",
      "Test steps: 76 10.65s test_loss: 0.056602 test_acc: 97.920998                                 \n",
      "step 555/1000\n",
      "Test steps: 76 10.73s test_loss: 0.079508 test_acc: 97.193347                                 \n",
      "step 556/1000\n",
      "Test steps: 76 10.71s test_loss: 0.070203 test_acc: 97.359667                                \n",
      "step 557/1000\n",
      "Test steps: 76 10.65s test_loss: 0.074319 test_acc: 97.234927                                \n",
      "step 558/1000\n",
      "Test steps: 76 10.64s test_loss: 0.068756 test_acc: 97.442827                                 \n",
      "step 559/1000\n",
      "Test steps: 76 10.65s test_loss: 0.068433 test_acc: 97.588358                                 \n",
      "step 560/1000\n",
      "Test steps: 76 10.61s test_loss: 0.079221 test_acc: 96.902287                                \n",
      "step 561/1000\n",
      "Test steps: 76 10.83s test_loss: 0.072770 test_acc: 97.484407                                 \n",
      "step 562/1000\n",
      "Test steps: 76 10.61s test_loss: 0.077733 test_acc: 97.047817                                 \n",
      "step 563/1000\n",
      "Test steps: 76 10.74s test_loss: 0.066025 test_acc: 97.463617                                \n",
      "step 564/1000\n",
      "Test steps: 76 10.73s test_loss: 0.061203 test_acc: 97.629938                                \n",
      "step 565/1000\n",
      "Test steps: 76 10.72s test_loss: 0.072494 test_acc: 97.401247                                 \n",
      "step 566/1000\n",
      "Test steps: 76 10.68s test_loss: 0.071971 test_acc: 97.401247                                 \n",
      "step 567/1000\n",
      "Test steps: 76 10.74s test_loss: 0.076357 test_acc: 97.463617                                 \n",
      "step 568/1000\n",
      "Test steps: 76 10.69s test_loss: 0.071964 test_acc: 97.359667                                 \n",
      "step 569/1000\n",
      "Test steps: 76 10.80s test_loss: 0.072379 test_acc: 97.422037                                 \n",
      "step 570/1000\n",
      "Test steps: 76 10.65s test_loss: 0.077554 test_acc: 97.193347                                 \n",
      "step 571/1000\n",
      "Test steps: 76 10.62s test_loss: 0.080305 test_acc: 96.923077                                 \n",
      "step 572/1000\n",
      "Test steps: 76 10.84s test_loss: 0.063599 test_acc: 97.505198                                 \n",
      "step 573/1000\n",
      "Test steps: 76 10.70s test_loss: 0.051560 test_acc: 98.066528                                 \n",
      "step 574/1000\n",
      "Test steps: 76 10.62s test_loss: 0.073171 test_acc: 97.338877                                 \n",
      "step 575/1000\n",
      "Test steps: 76 10.76s test_loss: 0.072623 test_acc: 97.609148                                 \n",
      "step 576/1000\n",
      "Test steps: 76 10.59s test_loss: 0.072938 test_acc: 97.338877                                \n",
      "step 577/1000\n",
      "Test steps: 76 10.73s test_loss: 0.078165 test_acc: 97.172557                                 \n",
      "step 578/1000\n",
      "Test steps: 76 10.64s test_loss: 0.074634 test_acc: 97.047817                                 \n",
      "step 579/1000\n",
      "Test steps: 76 10.78s test_loss: 0.067665 test_acc: 97.546778                                 \n",
      "step 580/1000\n",
      "Test steps: 76 10.79s test_loss: 0.070336 test_acc: 97.297297                                 \n",
      "step 581/1000\n",
      "Test steps: 76 10.56s test_loss: 0.070141 test_acc: 97.484407                                 \n",
      "step 582/1000\n",
      "Test steps: 76 10.62s test_loss: 0.075933 test_acc: 97.422037                                \n",
      "step 583/1000\n",
      "Test steps: 76 10.67s test_loss: 0.072357 test_acc: 97.359667                                 \n",
      "step 584/1000\n",
      "Test steps: 76 10.74s test_loss: 0.071185 test_acc: 97.380457                                 \n",
      "step 585/1000\n",
      "Test steps: 76 10.64s test_loss: 0.071284 test_acc: 97.401247                                 \n",
      "step 586/1000\n",
      "Test steps: 76 10.76s test_loss: 0.069582 test_acc: 97.318087                                \n",
      "step 587/1000\n",
      "Test steps: 76 10.68s test_loss: 0.072673 test_acc: 97.130977                                 \n",
      "step 588/1000\n",
      "Test steps: 76 10.71s test_loss: 0.076257 test_acc: 97.110187                                \n",
      "step 589/1000\n",
      "Test steps: 76 10.82s test_loss: 0.054617 test_acc: 97.817048                                 \n",
      "step 590/1000\n",
      "Test steps: 76 10.69s test_loss: 0.076270 test_acc: 97.110187                                 \n",
      "step 591/1000\n",
      "Test steps: 76 10.78s test_loss: 0.076652 test_acc: 96.964657                                 \n",
      "step 592/1000\n",
      "Test steps: 76 10.77s test_loss: 0.077491 test_acc: 97.047817                                \n",
      "step 593/1000\n",
      "Test steps: 76 10.66s test_loss: 0.075791 test_acc: 97.442827                                \n",
      "step 594/1000\n",
      "Test steps: 76 10.72s test_loss: 0.072224 test_acc: 97.255717                                 \n",
      "step 595/1000\n",
      "Test steps: 76 10.68s test_loss: 0.061917 test_acc: 97.671518                                \n",
      "step 596/1000\n",
      "Test steps: 76 10.64s test_loss: 0.069592 test_acc: 97.380457                                \n",
      "step 597/1000\n",
      "Test steps: 76 10.78s test_loss: 0.078611 test_acc: 97.089397                                \n",
      "step 598/1000\n",
      "Test steps: 76 10.66s test_loss: 0.074161 test_acc: 97.338877                                 \n",
      "step 599/1000\n",
      "Test steps: 76 10.61s test_loss: 0.084514 test_acc: 97.047817                                \n",
      "step 600/1000\n",
      "Test steps: 76 10.65s test_loss: 0.081284 test_acc: 96.943867                                 \n",
      "step 601/1000\n",
      "Test steps: 76 10.83s test_loss: 0.071984 test_acc: 97.401247                                 \n",
      "step 602/1000\n",
      "Test steps: 76 10.75s test_loss: 0.073551 test_acc: 97.401247                                 \n",
      "step 603/1000\n",
      "Test steps: 76 10.65s test_loss: 0.062383 test_acc: 97.588358                                 \n",
      "step 604/1000\n",
      "Test steps: 76 10.66s test_loss: 0.067652 test_acc: 97.505198                                 \n",
      "step 605/1000\n",
      "Test steps: 76 10.80s test_loss: 0.079684 test_acc: 97.422037                                 \n",
      "step 606/1000\n",
      "Test steps: 76 10.61s test_loss: 0.070488 test_acc: 97.442827                                 \n",
      "step 607/1000\n",
      "Test steps: 76 10.70s test_loss: 0.080951 test_acc: 97.234927                                 \n",
      "step 608/1000\n",
      "Test steps: 76 10.85s test_loss: 0.059763 test_acc: 97.858628                                 \n",
      "step 609/1000\n",
      "Test steps: 76 10.74s test_loss: 0.077876 test_acc: 97.193347                                \n",
      "step 610/1000\n",
      "Test steps: 76 10.67s test_loss: 0.081067 test_acc: 96.881497                                \n",
      "step 611/1000\n",
      "Test steps: 76 10.70s test_loss: 0.071139 test_acc: 97.401247                                 \n",
      "step 612/1000\n",
      "Test steps: 76 10.71s test_loss: 0.080158 test_acc: 97.422037                                 \n",
      "step 613/1000\n",
      "Test steps: 76 10.65s test_loss: 0.063695 test_acc: 97.671518                                \n",
      "step 614/1000\n",
      "Test steps: 76 10.74s test_loss: 0.081003 test_acc: 97.068607                                 \n",
      "step 615/1000\n",
      "Test steps: 76 10.66s test_loss: 0.065110 test_acc: 97.692308                                 \n",
      "step 616/1000\n",
      "Test steps: 76 10.60s test_loss: 0.074402 test_acc: 97.338877                                \n",
      "step 617/1000\n",
      "Test steps: 76 10.74s test_loss: 0.069216 test_acc: 97.442827                                 \n",
      "step 618/1000\n",
      "Test steps: 76 10.69s test_loss: 0.074862 test_acc: 97.193347                                \n",
      "step 619/1000\n",
      "Test steps: 76 10.65s test_loss: 0.065294 test_acc: 97.692308                                \n",
      "step 620/1000\n",
      "Test steps: 76 10.83s test_loss: 0.068932 test_acc: 97.130977                                 \n",
      "step 621/1000\n",
      "Test steps: 76 10.65s test_loss: 0.072062 test_acc: 97.401247                                 \n",
      "step 622/1000\n",
      "Test steps: 76 10.61s test_loss: 0.066230 test_acc: 97.671518                                \n",
      "step 623/1000\n",
      "Test steps: 76 10.80s test_loss: 0.084674 test_acc: 97.130977                                \n",
      "step 624/1000\n",
      "Test steps: 76 11.17s test_loss: 0.065098 test_acc: 97.796258                                \n",
      "step 625/1000\n",
      "Test steps: 76 10.81s test_loss: 0.079349 test_acc: 97.214137                                 \n",
      "step 626/1000\n",
      "Test steps: 76 10.63s test_loss: 0.074017 test_acc: 97.276507                                 \n",
      "step 627/1000\n",
      "Test steps: 76 10.72s test_loss: 0.068382 test_acc: 97.733888                                \n",
      "step 628/1000\n",
      "Test steps: 76 10.79s test_loss: 0.069279 test_acc: 97.567568                                 \n",
      "step 629/1000\n",
      "Test steps: 76 10.82s test_loss: 0.073888 test_acc: 97.151767                                 \n",
      "step 630/1000\n",
      "Test steps: 76 10.76s test_loss: 0.067266 test_acc: 97.276507                                 \n",
      "step 631/1000\n",
      "Test steps: 76 10.68s test_loss: 0.073622 test_acc: 97.567568                                \n",
      "step 632/1000\n",
      "Test steps: 76 10.75s test_loss: 0.063036 test_acc: 97.609148                                 \n",
      "step 633/1000\n",
      "Test steps: 76 10.85s test_loss: 0.073119 test_acc: 97.234927                                 \n",
      "step 634/1000\n",
      "Test steps: 76 10.82s test_loss: 0.069344 test_acc: 97.567568                                 \n",
      "step 635/1000\n",
      "Test steps: 76 10.76s test_loss: 0.077421 test_acc: 97.234927                                 \n",
      "step 636/1000\n",
      "Test steps: 76 10.77s test_loss: 0.077712 test_acc: 96.985447                                 \n",
      "step 637/1000\n",
      "Test steps: 76 10.83s test_loss: 0.074099 test_acc: 97.172557                                 \n",
      "step 638/1000\n",
      "Test steps: 76 10.97s test_loss: 0.081457 test_acc: 96.985447                                \n",
      "step 639/1000\n",
      "Test steps: 76 10.69s test_loss: 0.071175 test_acc: 97.463617                                 \n",
      "step 640/1000\n",
      "Test steps: 76 10.91s test_loss: 0.077578 test_acc: 97.234927                                 \n",
      "step 641/1000\n",
      "Test steps: 76 10.94s test_loss: 0.062590 test_acc: 97.650728                                 \n",
      "step 642/1000\n",
      "Test steps: 76 11.28s test_loss: 0.063756 test_acc: 97.733888                                 \n",
      "step 643/1000\n",
      "Test steps: 76 10.78s test_loss: 0.074309 test_acc: 97.525988                                 \n",
      "step 644/1000\n",
      "Test steps: 76 10.75s test_loss: 0.078205 test_acc: 97.297297                                \n",
      "step 645/1000\n",
      "Test steps: 76 10.59s test_loss: 0.059228 test_acc: 97.754678                                 \n",
      "step 646/1000\n",
      "Test steps: 76 10.93s test_loss: 0.068774 test_acc: 97.505198                                 \n",
      "step 647/1000\n",
      "Test steps: 76 10.63s test_loss: 0.074611 test_acc: 97.484407                                 \n",
      "step 648/1000\n",
      "Test steps: 76 10.51s test_loss: 0.076055 test_acc: 97.359667                                \n",
      "step 649/1000\n",
      "Test steps: 76 10.56s test_loss: 0.072508 test_acc: 97.255717                                 \n",
      "step 650/1000\n",
      "Test steps: 76 10.58s test_loss: 0.067525 test_acc: 97.609148                                 \n",
      "step 651/1000\n",
      "Test steps: 76 10.61s test_loss: 0.080613 test_acc: 97.089397                                \n",
      "step 652/1000\n",
      "Test steps: 76 10.67s test_loss: 0.077178 test_acc: 97.130977                                 \n",
      "step 653/1000\n",
      "Test steps: 76 10.59s test_loss: 0.068940 test_acc: 97.401247                                 \n",
      "step 654/1000\n",
      "Test steps: 76 10.66s test_loss: 0.067237 test_acc: 97.338877                                 \n",
      "step 655/1000\n",
      "Test steps: 76 10.57s test_loss: 0.080141 test_acc: 97.089397                                 \n",
      "step 656/1000\n",
      "Test steps: 76 10.57s test_loss: 0.079196 test_acc: 96.943867                                 \n",
      "step 657/1000\n",
      "Test steps: 76 10.72s test_loss: 0.075530 test_acc: 97.193347                                \n",
      "step 658/1000\n",
      "Test steps: 76 10.71s test_loss: 0.070077 test_acc: 97.546778                                 \n",
      "step 659/1000\n",
      "Test steps: 76 10.44s test_loss: 0.087197 test_acc: 96.798337                                 \n",
      "step 660/1000\n",
      "Test steps: 76 10.55s test_loss: 0.069819 test_acc: 97.463617                                 \n",
      "step 661/1000\n",
      "Test steps: 76 10.69s test_loss: 0.056561 test_acc: 97.920998                                 \n",
      "step 662/1000\n",
      "Test steps: 76 10.62s test_loss: 0.063414 test_acc: 97.733888                                \n",
      "step 663/1000\n",
      "Test steps: 76 10.61s test_loss: 0.070064 test_acc: 97.588358                                \n",
      "step 664/1000\n",
      "Test steps: 76 10.67s test_loss: 0.063913 test_acc: 97.380457                                 \n",
      "step 665/1000\n",
      "Test steps: 76 10.49s test_loss: 0.077326 test_acc: 97.193347                                 \n",
      "step 666/1000\n",
      "Test steps: 76 10.55s test_loss: 0.072587 test_acc: 97.338877                                 \n",
      "step 667/1000\n",
      "Test steps: 76 10.59s test_loss: 0.069078 test_acc: 97.733888                                \n",
      "step 668/1000\n",
      "Test steps: 76 10.54s test_loss: 0.072993 test_acc: 97.338877                                 \n",
      "step 669/1000\n",
      "Test steps: 76 10.56s test_loss: 0.074539 test_acc: 97.318087                                 \n",
      "step 670/1000\n",
      "Test steps: 76 10.68s test_loss: 0.061441 test_acc: 97.546778                                \n",
      "step 671/1000\n",
      "Test steps: 76 10.52s test_loss: 0.070231 test_acc: 97.609148                                 \n",
      "step 672/1000\n",
      "Test steps: 76 10.56s test_loss: 0.072937 test_acc: 97.297297                                 \n",
      "step 673/1000\n",
      "Test steps: 76 10.69s test_loss: 0.064608 test_acc: 97.796258                                 \n",
      "step 674/1000\n",
      "Test steps: 76 10.56s test_loss: 0.066595 test_acc: 97.609148                                 \n",
      "step 675/1000\n",
      "Test steps: 76 10.61s test_loss: 0.071017 test_acc: 97.338877                                \n",
      "step 676/1000\n",
      "Test steps: 76 10.54s test_loss: 0.078099 test_acc: 97.276507                                 \n",
      "step 677/1000\n",
      "Test steps: 76 10.53s test_loss: 0.068835 test_acc: 97.692308                                 \n",
      "step 678/1000\n",
      "Test steps: 76 10.59s test_loss: 0.070615 test_acc: 97.463617                                \n",
      "step 679/1000\n",
      "Test steps: 76 10.59s test_loss: 0.072703 test_acc: 97.297297                                 \n",
      "step 680/1000\n",
      "Test steps: 76 10.56s test_loss: 0.073473 test_acc: 97.380457                                \n",
      "step 681/1000\n",
      "Test steps: 76 10.61s test_loss: 0.070908 test_acc: 97.422037                                 \n",
      "step 682/1000\n",
      "Test steps: 76 10.49s test_loss: 0.073825 test_acc: 97.193347                                \n",
      "step 683/1000\n",
      "Test steps: 76 10.51s test_loss: 0.069379 test_acc: 97.650728                                 \n",
      "step 684/1000\n",
      "Test steps: 76 10.68s test_loss: 0.070519 test_acc: 97.484407                                \n",
      "step 685/1000\n",
      "Test steps: 76 10.67s test_loss: 0.066807 test_acc: 97.484407                                 \n",
      "step 686/1000\n",
      "Test steps: 76 10.60s test_loss: 0.086898 test_acc: 96.590437                                 \n",
      "step 687/1000\n",
      "Test steps: 76 10.64s test_loss: 0.066017 test_acc: 97.775468                                \n",
      "step 688/1000\n",
      "Test steps: 76 10.53s test_loss: 0.069256 test_acc: 97.297297                                 \n",
      "step 689/1000\n",
      "Test steps: 76 10.53s test_loss: 0.074392 test_acc: 97.359667                                 \n",
      "step 690/1000\n",
      "Test steps: 76 10.68s test_loss: 0.073785 test_acc: 97.338877                                 \n",
      "step 691/1000\n",
      "Test steps: 76 10.61s test_loss: 0.075280 test_acc: 97.422037                                \n",
      "step 692/1000\n",
      "Test steps: 76 10.60s test_loss: 0.073168 test_acc: 97.463617                                \n",
      "step 693/1000\n",
      "Test steps: 76 10.58s test_loss: 0.066557 test_acc: 97.484407                                \n",
      "step 694/1000\n",
      "Test steps: 76 10.59s test_loss: 0.058261 test_acc: 97.754678                                 \n",
      "step 695/1000\n",
      "Test steps: 76 10.65s test_loss: 0.073283 test_acc: 97.151767                                 \n",
      "step 696/1000\n",
      "Test steps: 76 10.56s test_loss: 0.083689 test_acc: 97.338877                                \n",
      "step 697/1000\n",
      "Test steps: 76 10.56s test_loss: 0.067341 test_acc: 97.463617                                \n",
      "step 698/1000\n",
      "Test steps: 76 10.63s test_loss: 0.064075 test_acc: 97.713098                                 \n",
      "step 699/1000\n",
      "Test steps: 76 10.73s test_loss: 0.072978 test_acc: 97.068607                                \n",
      "step 700/1000\n",
      "Test steps: 76 10.50s test_loss: 0.067691 test_acc: 97.650728                                \n",
      "step 701/1000\n",
      "Test steps: 76 10.62s test_loss: 0.069725 test_acc: 97.193347                                 \n",
      "step 702/1000\n",
      "Test steps: 76 10.53s test_loss: 0.078067 test_acc: 97.463617                                 \n",
      "step 703/1000\n",
      "Test steps: 76 10.51s test_loss: 0.067260 test_acc: 97.422037                                 \n",
      "step 704/1000\n",
      "Test steps: 76 10.66s test_loss: 0.070690 test_acc: 97.463617                                \n",
      "step 705/1000\n",
      "Test steps: 76 10.59s test_loss: 0.080028 test_acc: 97.151767                                \n",
      "step 706/1000\n",
      "Test steps: 76 10.59s test_loss: 0.066447 test_acc: 97.567568                                 \n",
      "step 707/1000\n",
      "Test steps: 76 10.66s test_loss: 0.071551 test_acc: 97.629938                                 \n",
      "step 708/1000\n",
      "Test steps: 76 10.63s test_loss: 0.069141 test_acc: 97.297297                                 \n",
      "step 709/1000\n",
      "Test steps: 76 10.62s test_loss: 0.074656 test_acc: 97.089397                                 \n",
      "step 710/1000\n",
      "Test steps: 76 10.55s test_loss: 0.068466 test_acc: 97.463617                                 \n",
      "step 711/1000\n",
      "Test steps: 76 10.53s test_loss: 0.071956 test_acc: 97.484407                                 \n",
      "step 712/1000\n",
      "Test steps: 76 10.65s test_loss: 0.066603 test_acc: 97.650728                                 \n",
      "step 713/1000\n",
      "Test steps: 76 10.63s test_loss: 0.062865 test_acc: 97.546778                                 \n",
      "step 714/1000\n",
      "Test steps: 76 10.53s test_loss: 0.073170 test_acc: 97.359667                                 \n",
      "step 715/1000\n",
      "Test steps: 76 10.59s test_loss: 0.060632 test_acc: 97.692308                                 \n",
      "step 716/1000\n",
      "Test steps: 76 10.59s test_loss: 0.075507 test_acc: 97.172557                                \n",
      "step 717/1000\n",
      "Test steps: 76 10.52s test_loss: 0.069341 test_acc: 97.546778                                 \n",
      "step 718/1000\n",
      "Test steps: 76 10.58s test_loss: 0.071164 test_acc: 97.276507                                 \n",
      "step 719/1000\n",
      "Test steps: 76 10.65s test_loss: 0.072277 test_acc: 97.796258                                \n",
      "step 720/1000\n",
      "Test steps: 76 10.60s test_loss: 0.075591 test_acc: 97.297297                                 \n",
      "step 721/1000\n",
      "Test steps: 76 10.68s test_loss: 0.075659 test_acc: 97.380457                                \n",
      "step 722/1000\n",
      "Test steps: 76 10.58s test_loss: 0.070855 test_acc: 97.546778                                \n",
      "step 723/1000\n",
      "Test steps: 76 10.61s test_loss: 0.073837 test_acc: 97.338877                                 \n",
      "step 724/1000\n",
      "Test steps: 76 10.70s test_loss: 0.054338 test_acc: 97.983368                                 \n",
      "step 725/1000\n",
      "Test steps: 76 10.64s test_loss: 0.075790 test_acc: 97.463617                                \n",
      "step 726/1000\n",
      "Test steps: 76 10.65s test_loss: 0.071642 test_acc: 97.318087                                \n",
      "step 727/1000\n",
      "Test steps: 76 10.57s test_loss: 0.068314 test_acc: 97.422037                                 \n",
      "step 728/1000\n",
      "Test steps: 76 10.56s test_loss: 0.063577 test_acc: 97.692308                                \n",
      "step 729/1000\n",
      "Test steps: 76 10.57s test_loss: 0.071514 test_acc: 97.338877                                 \n",
      "step 730/1000\n",
      "Test steps: 76 10.50s test_loss: 0.076896 test_acc: 97.006237                                \n",
      "step 731/1000\n",
      "Test steps: 76 10.59s test_loss: 0.070817 test_acc: 97.609148                                \n",
      "step 732/1000\n",
      "Test steps: 76 10.61s test_loss: 0.070872 test_acc: 97.463617                                 \n",
      "step 733/1000\n",
      "Test steps: 76 10.58s test_loss: 0.069902 test_acc: 97.463617                                 \n",
      "step 734/1000\n",
      "Test steps: 76 10.52s test_loss: 0.083543 test_acc: 96.985447                                \n",
      "step 735/1000\n",
      "Test steps: 76 10.65s test_loss: 0.075634 test_acc: 97.193347                                 \n",
      "step 736/1000\n",
      "Test steps: 76 10.71s test_loss: 0.062505 test_acc: 97.588358                                \n",
      "step 737/1000\n",
      "Test steps: 76 10.60s test_loss: 0.072568 test_acc: 97.276507                                 \n",
      "step 738/1000\n",
      "Test steps: 76 10.61s test_loss: 0.069049 test_acc: 97.505198                                 \n",
      "step 739/1000\n",
      "Test steps: 76 10.57s test_loss: 0.079125 test_acc: 97.193347                                \n",
      "step 740/1000\n",
      "Test steps: 76 10.61s test_loss: 0.076282 test_acc: 97.255717                                 \n",
      "step 741/1000\n",
      "Test steps: 76 10.71s test_loss: 0.075338 test_acc: 97.338877                                \n",
      "step 742/1000\n",
      "Test steps: 76 10.69s test_loss: 0.076108 test_acc: 97.297297                                \n",
      "step 743/1000\n",
      "Test steps: 76 10.63s test_loss: 0.069164 test_acc: 97.546778                                 \n",
      "step 744/1000\n",
      "Test steps: 76 10.59s test_loss: 0.065237 test_acc: 97.650728                                 \n",
      "step 745/1000\n",
      "Test steps: 76 10.52s test_loss: 0.071071 test_acc: 97.484407                                 \n",
      "step 746/1000\n",
      "Test steps: 76 10.57s test_loss: 0.067066 test_acc: 97.484407                                \n",
      "step 747/1000\n",
      "Test steps: 76 10.63s test_loss: 0.069698 test_acc: 97.422037                                \n",
      "step 748/1000\n",
      "Test steps: 76 10.59s test_loss: 0.060968 test_acc: 97.858628                                 \n",
      "step 749/1000\n",
      "Test steps: 76 10.61s test_loss: 0.071918 test_acc: 97.609148                                 \n",
      "step 750/1000\n",
      "Test steps: 76 10.48s test_loss: 0.073187 test_acc: 97.422037                                \n",
      "step 751/1000\n",
      "Test steps: 76 10.56s test_loss: 0.076744 test_acc: 97.442827                                 \n",
      "step 752/1000\n",
      "Test steps: 76 10.72s test_loss: 0.074014 test_acc: 97.318087                                 \n",
      "step 753/1000\n",
      "Test steps: 76 10.62s test_loss: 0.066101 test_acc: 97.525988                                 \n",
      "step 754/1000\n",
      "Test steps: 76 10.60s test_loss: 0.064804 test_acc: 97.713098                                 \n",
      "step 755/1000\n",
      "Test steps: 76 10.57s test_loss: 0.069875 test_acc: 97.359667                                 \n",
      "step 756/1000\n",
      "Test steps: 76 10.64s test_loss: 0.069962 test_acc: 97.193347                                 \n",
      "step 757/1000\n",
      "Test steps: 76 10.55s test_loss: 0.077974 test_acc: 97.193347                                 \n",
      "step 758/1000\n",
      "Test steps: 76 10.62s test_loss: 0.083878 test_acc: 96.881497                                \n",
      "step 759/1000\n",
      "Test steps: 76 10.54s test_loss: 0.072766 test_acc: 97.442827                                 \n",
      "step 760/1000\n",
      "Test steps: 76 10.69s test_loss: 0.068310 test_acc: 97.401247                                 \n",
      "step 761/1000\n",
      "Test steps: 76 10.60s test_loss: 0.070731 test_acc: 97.505198                                 \n",
      "step 762/1000\n",
      "Test steps: 76 10.54s test_loss: 0.070015 test_acc: 97.214137                                 \n",
      "step 763/1000\n",
      "Test steps: 76 10.71s test_loss: 0.064128 test_acc: 97.442827                                 \n",
      "step 764/1000\n",
      "Test steps: 76 10.67s test_loss: 0.077068 test_acc: 97.234927                                \n",
      "step 765/1000\n",
      "Test steps: 76 10.56s test_loss: 0.068588 test_acc: 97.463617                                 \n",
      "step 766/1000\n",
      "Test steps: 76 10.62s test_loss: 0.067007 test_acc: 97.609148                                 \n",
      "step 767/1000\n",
      "Test steps: 76 10.65s test_loss: 0.072432 test_acc: 97.733888                                 \n",
      "step 768/1000\n",
      "Test steps: 76 10.54s test_loss: 0.062860 test_acc: 97.713098                                 \n",
      "step 769/1000\n",
      "Test steps: 76 10.68s test_loss: 0.078633 test_acc: 97.214137                                \n",
      "step 770/1000\n",
      "Test steps: 76 10.63s test_loss: 0.061176 test_acc: 97.671518                                 \n",
      "step 771/1000\n",
      "Test steps: 76 10.65s test_loss: 0.074845 test_acc: 97.234927                                \n",
      "step 772/1000\n",
      "Test steps: 76 10.62s test_loss: 0.053521 test_acc: 97.879418                                \n",
      "step 773/1000\n",
      "Test steps: 76 10.59s test_loss: 0.080319 test_acc: 97.359667                                \n",
      "step 774/1000\n",
      "Test steps: 76 10.70s test_loss: 0.075780 test_acc: 97.151767                                \n",
      "step 775/1000\n",
      "Test steps: 76 10.57s test_loss: 0.077925 test_acc: 97.027027                                \n",
      "step 776/1000\n",
      "Test steps: 76 10.66s test_loss: 0.069167 test_acc: 97.442827                                \n",
      "step 777/1000\n",
      "Test steps: 76 10.70s test_loss: 0.067576 test_acc: 97.484407                                 \n",
      "step 778/1000\n",
      "Test steps: 76 10.60s test_loss: 0.079714 test_acc: 97.422037                                 \n",
      "step 779/1000\n",
      "Test steps: 76 10.60s test_loss: 0.066479 test_acc: 97.463617                                \n",
      "step 780/1000\n",
      "Test steps: 76 10.62s test_loss: 0.074725 test_acc: 97.047817                                \n",
      "step 781/1000\n",
      "Test steps: 76 10.67s test_loss: 0.075887 test_acc: 97.027027                                \n",
      "step 782/1000\n",
      "Test steps: 76 10.56s test_loss: 0.079982 test_acc: 96.860707                                \n",
      "step 783/1000\n",
      "Test steps: 76 10.63s test_loss: 0.065061 test_acc: 97.609148                                 \n",
      "step 784/1000\n",
      "Test steps: 76 10.60s test_loss: 0.063219 test_acc: 97.713098                                \n",
      "step 785/1000\n",
      "Test steps: 76 10.66s test_loss: 0.066463 test_acc: 97.338877                                \n",
      "step 786/1000\n",
      "Test steps: 76 10.56s test_loss: 0.073134 test_acc: 97.588358                                \n",
      "step 787/1000\n",
      "Test steps: 76 10.62s test_loss: 0.067891 test_acc: 97.609148                                 \n",
      "step 788/1000\n",
      "Test steps: 76 10.55s test_loss: 0.073629 test_acc: 97.484407                                 \n",
      "step 789/1000\n",
      "Test steps: 76 10.58s test_loss: 0.071682 test_acc: 97.505198                                \n",
      "step 790/1000\n",
      "Test steps: 76 10.52s test_loss: 0.075699 test_acc: 97.484407                                \n",
      "step 791/1000\n",
      "Test steps: 76 10.59s test_loss: 0.074024 test_acc: 97.255717                                 \n",
      "step 792/1000\n",
      "Test steps: 76 10.53s test_loss: 0.070896 test_acc: 97.609148                                 \n",
      "step 793/1000\n",
      "Test steps: 76 10.64s test_loss: 0.064213 test_acc: 97.609148                                 \n",
      "step 794/1000\n",
      "Test steps: 76 10.64s test_loss: 0.082332 test_acc: 97.172557                                \n",
      "step 795/1000\n",
      "Test steps: 76 10.53s test_loss: 0.080651 test_acc: 97.151767                                \n",
      "step 796/1000\n",
      "Test steps: 76 10.58s test_loss: 0.068168 test_acc: 97.276507                                 \n",
      "step 797/1000\n",
      "Test steps: 76 10.62s test_loss: 0.081365 test_acc: 96.985447                                \n",
      "step 798/1000\n",
      "Test steps: 76 10.64s test_loss: 0.072224 test_acc: 97.713098                                 \n",
      "step 799/1000\n",
      "Test steps: 76 10.60s test_loss: 0.076989 test_acc: 97.089397                                 \n",
      "step 800/1000\n",
      "Test steps: 76 10.60s test_loss: 0.069594 test_acc: 97.733888                                 \n",
      "step 801/1000\n",
      "Test steps: 76 10.63s test_loss: 0.066411 test_acc: 97.442827                                 \n",
      "step 802/1000\n",
      "Test steps: 76 10.55s test_loss: 0.077701 test_acc: 97.193347                                \n",
      "step 803/1000\n",
      "Test steps: 76 10.64s test_loss: 0.066969 test_acc: 97.713098                                \n",
      "step 804/1000\n",
      "Test steps: 76 10.61s test_loss: 0.068483 test_acc: 97.442827                                 \n",
      "step 805/1000\n",
      "Test steps: 76 10.63s test_loss: 0.073072 test_acc: 97.588358                                 \n",
      "step 806/1000\n",
      "Test steps: 76 10.54s test_loss: 0.074179 test_acc: 97.338877                                \n",
      "step 807/1000\n",
      "Test steps: 76 10.72s test_loss: 0.072458 test_acc: 97.422037                                \n",
      "step 808/1000\n",
      "Test steps: 76 10.66s test_loss: 0.080732 test_acc: 97.442827                                \n",
      "step 809/1000\n",
      "Test steps: 76 10.56s test_loss: 0.070794 test_acc: 97.130977                                \n",
      "step 810/1000\n",
      "Test steps: 76 10.66s test_loss: 0.080583 test_acc: 97.006237                                 \n",
      "step 811/1000\n",
      "Test steps: 76 10.67s test_loss: 0.070839 test_acc: 97.442827                                 \n",
      "step 812/1000\n",
      "Test steps: 76 10.59s test_loss: 0.083072 test_acc: 97.110187                                \n",
      "step 813/1000\n",
      "Test steps: 76 10.65s test_loss: 0.057507 test_acc: 97.775468                                 \n",
      "step 814/1000\n",
      "Test steps: 76 10.65s test_loss: 0.060646 test_acc: 98.045738                                 \n",
      "step 815/1000\n",
      "Test steps: 76 10.56s test_loss: 0.071094 test_acc: 97.401247                                \n",
      "step 816/1000\n",
      "Test steps: 76 10.65s test_loss: 0.070467 test_acc: 97.234927                                \n",
      "step 817/1000\n",
      "Test steps: 76 10.60s test_loss: 0.068304 test_acc: 97.692308                                 \n",
      "step 818/1000\n",
      "Test steps: 76 10.59s test_loss: 0.072712 test_acc: 97.588358                                \n",
      "step 819/1000\n",
      "Test steps: 76 10.59s test_loss: 0.065371 test_acc: 97.588358                                 \n",
      "step 820/1000\n",
      "Test steps: 76 10.73s test_loss: 0.078211 test_acc: 97.047817                                 \n",
      "step 821/1000\n",
      "Test steps: 76 10.63s test_loss: 0.077571 test_acc: 97.234927                                \n",
      "step 822/1000\n",
      "Test steps: 76 10.61s test_loss: 0.080951 test_acc: 97.193347                                 \n",
      "step 823/1000\n",
      "Test steps: 76 10.60s test_loss: 0.065291 test_acc: 97.775468                                 \n",
      "step 824/1000\n",
      "Test steps: 76 10.57s test_loss: 0.061715 test_acc: 97.629938                                \n",
      "step 825/1000\n",
      "Test steps: 76 10.64s test_loss: 0.076039 test_acc: 97.297297                                \n",
      "step 826/1000\n",
      "Test steps: 76 10.55s test_loss: 0.068238 test_acc: 97.463617                                \n",
      "step 827/1000\n",
      "Test steps: 76 10.70s test_loss: 0.077597 test_acc: 97.359667                                 \n",
      "step 828/1000\n",
      "Test steps: 76 10.64s test_loss: 0.074827 test_acc: 97.318087                                 \n",
      "step 829/1000\n",
      "Test steps: 76 10.67s test_loss: 0.079078 test_acc: 97.110187                                \n",
      "step 830/1000\n",
      "Test steps: 76 10.59s test_loss: 0.075102 test_acc: 97.380457                                \n",
      "step 831/1000\n",
      "Test steps: 76 10.67s test_loss: 0.077466 test_acc: 97.068607                                \n",
      "step 832/1000\n",
      "Test steps: 76 10.70s test_loss: 0.082437 test_acc: 96.964657                                \n",
      "step 833/1000\n",
      "Test steps: 76 10.59s test_loss: 0.067417 test_acc: 97.588358                                 \n",
      "step 834/1000\n",
      "Test steps: 76 10.65s test_loss: 0.058950 test_acc: 97.713098                                \n",
      "step 835/1000\n",
      "Test steps: 76 10.65s test_loss: 0.080496 test_acc: 97.422037                                 \n",
      "step 836/1000\n",
      "Test steps: 76 10.56s test_loss: 0.072506 test_acc: 97.505198                                 \n",
      "step 837/1000\n",
      "Test steps: 76 10.63s test_loss: 0.083842 test_acc: 97.089397                                \n",
      "step 838/1000\n",
      "Test steps: 76 10.67s test_loss: 0.075251 test_acc: 97.422037                                \n",
      "step 839/1000\n",
      "Test steps: 76 10.64s test_loss: 0.064670 test_acc: 97.567568                                 \n",
      "step 840/1000\n",
      "Test steps: 76 10.55s test_loss: 0.075493 test_acc: 97.401247                                 \n",
      "step 841/1000\n",
      "Test steps: 76 10.66s test_loss: 0.072287 test_acc: 97.505198                                 \n",
      "step 842/1000\n",
      "Test steps: 76 10.69s test_loss: 0.076487 test_acc: 97.276507                                \n",
      "step 843/1000\n",
      "Test steps: 76 10.62s test_loss: 0.071380 test_acc: 97.359667                                \n",
      "step 844/1000\n",
      "Test steps: 76 10.59s test_loss: 0.075753 test_acc: 97.151767                                 \n",
      "step 845/1000\n",
      "Test steps: 76 10.75s test_loss: 0.069999 test_acc: 97.442827                                 \n",
      "step 846/1000\n",
      "Test steps: 76 10.94s test_loss: 0.068166 test_acc: 97.546778                                 \n",
      "step 847/1000\n",
      "Test steps: 76 10.53s test_loss: 0.078710 test_acc: 97.089397                                \n",
      "step 848/1000\n",
      "Test steps: 76 10.60s test_loss: 0.071759 test_acc: 97.318087                                 \n",
      "step 849/1000\n",
      "Test steps: 76 10.78s test_loss: 0.072103 test_acc: 97.422037                                 \n",
      "step 850/1000\n",
      "Test steps: 76 10.63s test_loss: 0.072703 test_acc: 97.463617                                 \n",
      "step 851/1000\n",
      "Test steps: 76 10.73s test_loss: 0.079349 test_acc: 96.985447                                 \n",
      "step 852/1000\n",
      "Test steps: 76 10.57s test_loss: 0.072316 test_acc: 97.234927                                \n",
      "step 853/1000\n",
      "Test steps: 76 10.68s test_loss: 0.075797 test_acc: 97.380457                                \n",
      "step 854/1000\n",
      "Test steps: 76 10.61s test_loss: 0.066168 test_acc: 97.505198                                \n",
      "step 855/1000\n",
      "Test steps: 76 10.74s test_loss: 0.066705 test_acc: 97.713098                                \n",
      "step 856/1000\n",
      "Test steps: 76 10.71s test_loss: 0.070207 test_acc: 97.567568                                \n",
      "step 857/1000\n",
      "Test steps: 76 10.57s test_loss: 0.073928 test_acc: 97.463617                                \n",
      "step 858/1000\n",
      "Test steps: 76 10.65s test_loss: 0.071976 test_acc: 97.401247                                 \n",
      "step 859/1000\n",
      "Test steps: 76 10.63s test_loss: 0.069562 test_acc: 97.546778                                 \n",
      "step 860/1000\n",
      "Test steps: 76 10.72s test_loss: 0.073801 test_acc: 97.110187                                \n",
      "step 861/1000\n",
      "Test steps: 76 10.68s test_loss: 0.068078 test_acc: 97.463617                                 \n",
      "step 862/1000\n",
      "Test steps: 76 10.61s test_loss: 0.055758 test_acc: 97.817048                                 \n",
      "step 863/1000\n",
      "Test steps: 76 10.58s test_loss: 0.061558 test_acc: 97.941788                                 \n",
      "step 864/1000\n",
      "Test steps: 76 10.56s test_loss: 0.071748 test_acc: 97.484407                                 \n",
      "step 865/1000\n",
      "Test steps: 76 10.68s test_loss: 0.065971 test_acc: 97.650728                                 \n",
      "step 866/1000\n",
      "Test steps: 76 10.63s test_loss: 0.066516 test_acc: 97.609148                                \n",
      "step 867/1000\n",
      "Test steps: 76 10.67s test_loss: 0.065995 test_acc: 97.629938                                 \n",
      "step 868/1000\n",
      "Test steps: 76 10.71s test_loss: 0.068421 test_acc: 97.588358                                 \n",
      "step 869/1000\n",
      "Test steps: 76 10.58s test_loss: 0.069931 test_acc: 97.546778                                 \n",
      "step 870/1000\n",
      "Test steps: 76 10.77s test_loss: 0.071565 test_acc: 97.276507                                 \n",
      "step 871/1000\n",
      "Test steps: 76 10.62s test_loss: 0.068387 test_acc: 97.733888                                 \n",
      "step 872/1000\n",
      "Test steps: 76 10.56s test_loss: 0.067384 test_acc: 97.338877                                 \n",
      "step 873/1000\n",
      "Test steps: 76 10.66s test_loss: 0.071036 test_acc: 97.214137                                 \n",
      "step 874/1000\n",
      "Test steps: 76 10.57s test_loss: 0.072121 test_acc: 97.422037                                \n",
      "step 875/1000\n",
      "Test steps: 76 10.59s test_loss: 0.069726 test_acc: 97.338877                                \n",
      "step 876/1000\n",
      "Test steps: 76 10.62s test_loss: 0.074040 test_acc: 97.297297                                \n",
      "step 877/1000\n",
      "Test steps: 76 10.68s test_loss: 0.071321 test_acc: 97.297297                                 \n",
      "step 878/1000\n",
      "Test steps: 76 10.62s test_loss: 0.079447 test_acc: 97.234927                                 \n",
      "step 879/1000\n",
      "Test steps: 76 10.70s test_loss: 0.070553 test_acc: 97.463617                                 \n",
      "step 880/1000\n",
      "Test steps: 76 10.60s test_loss: 0.070562 test_acc: 97.525988                                 \n",
      "step 881/1000\n",
      "Test steps: 76 10.64s test_loss: 0.064061 test_acc: 97.609148                                 \n",
      "step 882/1000\n",
      "Test steps: 76 10.66s test_loss: 0.065626 test_acc: 97.775468                                 \n",
      "step 883/1000\n",
      "Test steps: 76 10.62s test_loss: 0.067919 test_acc: 97.214137                                \n",
      "step 884/1000\n",
      "Test steps: 76 10.71s test_loss: 0.083012 test_acc: 97.193347                                \n",
      "step 885/1000\n",
      "Test steps: 76 10.57s test_loss: 0.073672 test_acc: 97.318087                                \n",
      "step 886/1000\n",
      "Test steps: 76 10.55s test_loss: 0.066474 test_acc: 97.754678                                 \n",
      "step 887/1000\n",
      "Test steps: 76 10.70s test_loss: 0.073592 test_acc: 97.214137                                 \n",
      "step 888/1000\n",
      "Test steps: 76 10.61s test_loss: 0.064821 test_acc: 97.546778                                 \n",
      "step 889/1000\n",
      "Test steps: 76 10.59s test_loss: 0.077613 test_acc: 97.130977                                 \n",
      "step 890/1000\n",
      "Test steps: 76 10.69s test_loss: 0.074702 test_acc: 97.193347                                 \n",
      "step 891/1000\n",
      "Test steps: 76 10.53s test_loss: 0.079975 test_acc: 97.193347                                \n",
      "step 892/1000\n",
      "Test steps: 76 10.65s test_loss: 0.067039 test_acc: 97.401247                                 \n",
      "step 893/1000\n",
      "Test steps: 76 10.65s test_loss: 0.065427 test_acc: 97.505198                                \n",
      "step 894/1000\n",
      "Test steps: 76 10.69s test_loss: 0.076700 test_acc: 97.297297                                 \n",
      "step 895/1000\n",
      "Test steps: 76 10.59s test_loss: 0.070596 test_acc: 97.422037                                \n",
      "step 896/1000\n",
      "Test steps: 76 10.65s test_loss: 0.072664 test_acc: 97.442827                                \n",
      "step 897/1000\n",
      "Test steps: 76 10.63s test_loss: 0.083525 test_acc: 97.110187                                \n",
      "step 898/1000\n",
      "Test steps: 76 10.68s test_loss: 0.071159 test_acc: 97.338877                                \n",
      "step 899/1000\n",
      "Test steps: 76 10.66s test_loss: 0.069608 test_acc: 97.484407                                \n",
      "step 900/1000\n",
      "Test steps: 76 10.66s test_loss: 0.082681 test_acc: 96.902287                                \n",
      "step 901/1000\n",
      "Test steps: 76 10.73s test_loss: 0.075200 test_acc: 97.484407                                \n",
      "step 902/1000\n",
      "Test steps: 76 10.60s test_loss: 0.075263 test_acc: 97.588358                                \n",
      "step 903/1000\n",
      "Test steps: 76 10.63s test_loss: 0.060513 test_acc: 97.962578                                \n",
      "step 904/1000\n",
      "Test steps: 76 10.61s test_loss: 0.076180 test_acc: 97.422037                                \n",
      "step 905/1000\n",
      "Test steps: 76 10.68s test_loss: 0.067782 test_acc: 97.609148                                 \n",
      "step 906/1000\n",
      "Test steps: 76 10.63s test_loss: 0.069528 test_acc: 97.609148                                 \n",
      "step 907/1000\n",
      "Test steps: 76 10.75s test_loss: 0.072883 test_acc: 97.276507                                \n",
      "step 908/1000\n",
      "Test steps: 76 10.61s test_loss: 0.074342 test_acc: 97.276507                                \n",
      "step 909/1000\n",
      "Test steps: 76 10.59s test_loss: 0.061265 test_acc: 97.920998                                \n",
      "step 910/1000\n",
      "Test steps: 76 10.59s test_loss: 0.069481 test_acc: 97.463617                                \n",
      "step 911/1000\n",
      "Test steps: 76 10.66s test_loss: 0.079447 test_acc: 97.151767                                \n",
      "step 912/1000\n",
      "Test steps: 76 10.55s test_loss: 0.075754 test_acc: 97.401247                                 \n",
      "step 913/1000\n",
      "Test steps: 76 10.72s test_loss: 0.066743 test_acc: 97.484407                                 \n",
      "step 914/1000\n",
      "Test steps: 76 10.58s test_loss: 0.074475 test_acc: 97.359667                                \n",
      "step 915/1000\n",
      "Test steps: 76 10.59s test_loss: 0.062270 test_acc: 97.671518                                \n",
      "step 916/1000\n",
      "Test steps: 76 10.73s test_loss: 0.066758 test_acc: 97.463617                                \n",
      "step 917/1000\n",
      "Test steps: 76 10.65s test_loss: 0.080346 test_acc: 97.172557                                \n",
      "step 918/1000\n",
      "Test steps: 76 10.66s test_loss: 0.063041 test_acc: 97.775468                                \n",
      "step 919/1000\n",
      "Test steps: 76 10.62s test_loss: 0.068415 test_acc: 97.442827                                 \n",
      "step 920/1000\n",
      "Test steps: 76 10.63s test_loss: 0.070578 test_acc: 97.110187                                \n",
      "step 921/1000\n",
      "Test steps: 76 10.64s test_loss: 0.075276 test_acc: 97.214137                                 \n",
      "step 922/1000\n",
      "Test steps: 76 10.73s test_loss: 0.080749 test_acc: 96.839917                                 \n",
      "step 923/1000\n",
      "Test steps: 76 10.57s test_loss: 0.077750 test_acc: 97.151767                                \n",
      "step 924/1000\n",
      "Test steps: 76 10.68s test_loss: 0.074326 test_acc: 97.297297                                 \n",
      "step 925/1000\n",
      "Test steps: 76 10.63s test_loss: 0.074848 test_acc: 97.463617                                 \n",
      "step 926/1000\n",
      "Test steps: 76 10.55s test_loss: 0.070124 test_acc: 97.338877                                \n",
      "step 927/1000\n",
      "Test steps: 76 10.70s test_loss: 0.068016 test_acc: 97.671518                                 \n",
      "step 928/1000\n",
      "Test steps: 76 10.61s test_loss: 0.077697 test_acc: 97.255717                                \n",
      "step 929/1000\n",
      "Test steps: 76 10.67s test_loss: 0.059796 test_acc: 97.775468                                 \n",
      "step 930/1000\n",
      "Test steps: 76 10.53s test_loss: 0.073321 test_acc: 97.463617                                 \n",
      "step 931/1000\n",
      "Test steps: 76 10.62s test_loss: 0.057412 test_acc: 97.692308                                 \n",
      "step 932/1000\n",
      "Test steps: 76 10.74s test_loss: 0.083478 test_acc: 96.964657                                 \n",
      "step 933/1000\n",
      "Test steps: 76 10.61s test_loss: 0.072452 test_acc: 97.567568                                 \n",
      "step 934/1000\n",
      "Test steps: 76 10.64s test_loss: 0.056558 test_acc: 97.817048                                 \n",
      "step 935/1000\n",
      "Test steps: 76 10.75s test_loss: 0.077719 test_acc: 97.151767                                 \n",
      "step 936/1000\n",
      "Test steps: 76 10.65s test_loss: 0.070439 test_acc: 97.297297                                \n",
      "step 937/1000\n",
      "Test steps: 76 10.58s test_loss: 0.071780 test_acc: 97.463617                                 \n",
      "step 938/1000\n",
      "Test steps: 76 10.68s test_loss: 0.074644 test_acc: 97.463617                                 \n",
      "step 939/1000\n",
      "Test steps: 76 10.63s test_loss: 0.078839 test_acc: 97.089397                                 \n",
      "step 940/1000\n",
      "Test steps: 76 10.63s test_loss: 0.077895 test_acc: 96.798337                                 \n",
      "step 941/1000\n",
      "Test steps: 76 10.69s test_loss: 0.069550 test_acc: 97.484407                                \n",
      "step 942/1000\n",
      "Test steps: 76 10.60s test_loss: 0.068096 test_acc: 97.629938                                 \n",
      "step 943/1000\n",
      "Test steps: 76 10.62s test_loss: 0.068151 test_acc: 97.546778                                \n",
      "step 944/1000\n",
      "Test steps: 76 10.62s test_loss: 0.070637 test_acc: 97.401247                                 \n",
      "step 945/1000\n",
      "Test steps: 76 10.74s test_loss: 0.075460 test_acc: 97.359667                                 \n",
      "step 946/1000\n",
      "Test steps: 76 10.69s test_loss: 0.074066 test_acc: 97.255717                                \n",
      "step 947/1000\n",
      "Test steps: 76 10.67s test_loss: 0.062840 test_acc: 97.775468                                 \n",
      "step 948/1000\n",
      "Test steps: 76 10.62s test_loss: 0.068450 test_acc: 97.546778                                \n",
      "step 949/1000\n",
      "Test steps: 76 10.59s test_loss: 0.070191 test_acc: 97.505198                                \n",
      "step 950/1000\n",
      "Test steps: 76 10.68s test_loss: 0.080808 test_acc: 96.881497                                \n",
      "step 951/1000\n",
      "Test steps: 76 10.66s test_loss: 0.078317 test_acc: 97.047817                                \n",
      "step 952/1000\n",
      "Test steps: 76 10.69s test_loss: 0.083222 test_acc: 97.130977                                \n",
      "step 953/1000\n",
      "Test steps: 76 10.56s test_loss: 0.073868 test_acc: 97.234927                                \n",
      "step 954/1000\n",
      "Test steps: 76 10.66s test_loss: 0.065818 test_acc: 97.525988                                 \n",
      "step 955/1000\n",
      "Test steps: 76 10.77s test_loss: 0.068157 test_acc: 97.754678                                 \n",
      "step 956/1000\n",
      "Test steps: 76 10.64s test_loss: 0.071590 test_acc: 97.442827                                \n",
      "step 957/1000\n",
      "Test steps: 76 10.70s test_loss: 0.060297 test_acc: 97.629938                                 \n",
      "step 958/1000\n",
      "Test steps: 76 10.60s test_loss: 0.081168 test_acc: 96.860707                                \n",
      "step 959/1000\n",
      "Test steps: 76 10.70s test_loss: 0.083496 test_acc: 97.068607                                 \n",
      "step 960/1000\n",
      "Test steps: 76 10.67s test_loss: 0.066169 test_acc: 97.692308                                \n",
      "step 961/1000\n",
      "Test steps: 76 10.64s test_loss: 0.072507 test_acc: 97.713098                                 \n",
      "step 962/1000\n",
      "Test steps: 76 10.76s test_loss: 0.071624 test_acc: 97.588358                                 \n",
      "step 963/1000\n",
      "Test steps: 76 10.72s test_loss: 0.072925 test_acc: 97.276507                                \n",
      "step 964/1000\n",
      "Test steps: 76 10.66s test_loss: 0.070557 test_acc: 97.442827                                 \n",
      "step 965/1000\n",
      "Test steps: 76 10.58s test_loss: 0.069411 test_acc: 97.650728                                \n",
      "step 966/1000\n",
      "Test steps: 76 10.58s test_loss: 0.079127 test_acc: 97.089397                                \n",
      "step 967/1000\n",
      "Test steps: 76 10.71s test_loss: 0.071130 test_acc: 97.401247                                \n",
      "step 968/1000\n",
      "Test steps: 76 10.54s test_loss: 0.068842 test_acc: 97.505198                                 \n",
      "step 969/1000\n",
      "Test steps: 76 10.63s test_loss: 0.068326 test_acc: 97.359667                                 \n",
      "step 970/1000\n",
      "Test steps: 76 10.66s test_loss: 0.078278 test_acc: 97.151767                                 \n",
      "step 971/1000\n",
      "Test steps: 76 10.59s test_loss: 0.090347 test_acc: 97.047817                                \n",
      "step 972/1000\n",
      "Test steps: 76 10.65s test_loss: 0.074186 test_acc: 97.234927                                \n",
      "step 973/1000\n",
      "Test steps: 76 10.64s test_loss: 0.076413 test_acc: 97.359667                                \n",
      "step 974/1000\n",
      "Test steps: 76 10.58s test_loss: 0.073621 test_acc: 97.089397                                 \n",
      "step 975/1000\n",
      "Test steps: 76 10.64s test_loss: 0.069281 test_acc: 97.255717                                 \n",
      "step 976/1000\n",
      "Test steps: 76 10.70s test_loss: 0.084480 test_acc: 96.923077                                 \n",
      "step 977/1000\n",
      "Test steps: 76 10.70s test_loss: 0.071628 test_acc: 97.671518                                \n",
      "step 978/1000\n",
      "Test steps: 76 10.60s test_loss: 0.062740 test_acc: 97.837838                                \n",
      "step 979/1000\n",
      "Test steps: 76 10.64s test_loss: 0.075182 test_acc: 97.297297                                \n",
      "step 980/1000\n",
      "Test steps: 76 10.70s test_loss: 0.072049 test_acc: 97.505198                                \n",
      "step 981/1000\n",
      "Test steps: 76 10.61s test_loss: 0.074581 test_acc: 97.318087                                 \n",
      "step 982/1000\n",
      "Test steps: 76 10.64s test_loss: 0.070283 test_acc: 97.422037                                 \n",
      "step 983/1000\n",
      "Test steps: 76 10.75s test_loss: 0.070788 test_acc: 97.338877                                 \n",
      "step 984/1000\n",
      "Test steps: 76 10.65s test_loss: 0.076502 test_acc: 97.297297                                \n",
      "step 985/1000\n",
      "Test steps: 76 10.66s test_loss: 0.064481 test_acc: 97.692308                                 \n",
      "step 986/1000\n",
      "Test steps: 76 10.66s test_loss: 0.077275 test_acc: 97.193347                                \n",
      "step 987/1000\n",
      "Test steps: 76 10.56s test_loss: 0.076824 test_acc: 97.318087                                 \n",
      "step 988/1000\n",
      "Test steps: 76 10.66s test_loss: 0.063397 test_acc: 97.609148                                 \n",
      "step 989/1000\n",
      "Test steps: 76 10.69s test_loss: 0.072958 test_acc: 97.567568                                 \n",
      "step 990/1000\n",
      "Test steps: 76 10.63s test_loss: 0.083056 test_acc: 96.881497                                \n",
      "step 991/1000\n",
      "Test steps: 76 10.66s test_loss: 0.064377 test_acc: 97.671518                                \n",
      "step 992/1000\n",
      "Test steps: 76 10.56s test_loss: 0.065989 test_acc: 97.609148                                 \n",
      "step 993/1000\n",
      "Test steps: 76 10.62s test_loss: 0.067401 test_acc: 97.650728                                 \n",
      "step 994/1000\n",
      "Test steps: 76 10.63s test_loss: 0.081777 test_acc: 96.964657                                \n",
      "step 995/1000\n",
      "Test steps: 76 10.64s test_loss: 0.071543 test_acc: 97.609148                                \n",
      "step 996/1000\n",
      "Test steps: 76 10.68s test_loss: 0.076212 test_acc: 97.047817                                \n",
      "step 997/1000\n",
      "Test steps: 76 10.70s test_loss: 0.070961 test_acc: 97.193347                                 \n",
      "step 998/1000\n",
      "Test steps: 76 10.65s test_loss: 0.072505 test_acc: 97.401247                                 \n",
      "step 999/1000\n",
      "Test steps: 76 10.60s test_loss: 0.081578 test_acc: 97.380457                                \n",
      "step 1000/1000\n",
      "Test steps: 76 10.72s test_loss: 0.080249 test_acc: 96.943867                                \n"
     ]
    }
   ],
   "source": [
    "new_row =  bootstrap_evaluation_poutyne(model=poutyne_model, seed=42, \n",
    "                             data=external_data,\n",
    "                             save_logs=True, \n",
    "                             n_bootstraps=1000,\n",
    "                             tb_class_index=tb_class_index,\n",
    "                             results_dir='external_bootstrap_results1k_new/truncated_b0_act1_reduced_layers_3_2025-03-16_13-28')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>accuracy_lower_ci</th>\n",
       "      <th>accuracy_upper_ci</th>\n",
       "      <th>f1_score_mean</th>\n",
       "      <th>f1_score_lower_ci</th>\n",
       "      <th>f1_score_upper_ci</th>\n",
       "      <th>sensitivity_mean</th>\n",
       "      <th>sensitivity_lower_ci</th>\n",
       "      <th>sensitivity_upper_ci</th>\n",
       "      <th>specificity_mean</th>\n",
       "      <th>specificity_lower_ci</th>\n",
       "      <th>specificity_upper_ci</th>\n",
       "      <th>loss_mean</th>\n",
       "      <th>loss_lower_ci</th>\n",
       "      <th>loss_upper_ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97.392495</td>\n",
       "      <td>96.943347</td>\n",
       "      <td>97.837838</td>\n",
       "      <td>0.973039</td>\n",
       "      <td>0.968211</td>\n",
       "      <td>0.977717</td>\n",
       "      <td>0.989652</td>\n",
       "      <td>0.985317</td>\n",
       "      <td>0.993228</td>\n",
       "      <td>0.956985</td>\n",
       "      <td>0.948695</td>\n",
       "      <td>0.964807</td>\n",
       "      <td>0.071865</td>\n",
       "      <td>0.059795</td>\n",
       "      <td>0.083496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy_mean  accuracy_lower_ci  accuracy_upper_ci  f1_score_mean  \\\n",
       "0      97.392495          96.943347          97.837838       0.973039   \n",
       "\n",
       "   f1_score_lower_ci  f1_score_upper_ci  sensitivity_mean  \\\n",
       "0           0.968211           0.977717          0.989652   \n",
       "\n",
       "   sensitivity_lower_ci  sensitivity_upper_ci  specificity_mean  \\\n",
       "0              0.985317              0.993228          0.956985   \n",
       "\n",
       "   specificity_lower_ci  specificity_upper_ci  loss_mean  loss_lower_ci  \\\n",
       "0              0.948695              0.964807   0.071865       0.059795   \n",
       "\n",
       "   loss_upper_ci  \n",
       "0       0.083496  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
