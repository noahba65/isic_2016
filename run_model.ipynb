{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from poutyne import Model, CSVLogger\n",
    "from poutyne.framework import ModelCheckpoint, EarlyStopping, plot_history\n",
    "import numpy as np\n",
    "import torchmetrics\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import pandas as pd\n",
    "from custom_lib.custom_models.basic_nn import NeuralNetwork\n",
    "from custom_lib.data_prep import data_transformation_pipeline, data_loader\n",
    "import matplotlib as plt\n",
    "import torchvision.models as models\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuneable Params\n",
    "lr = 1e-3\n",
    "data_dir = \"data_3_class\"\n",
    "model_name = \"truncated_b0_leaky\" \n",
    "image_size = 224\n",
    "center_crop = 224\n",
    "save_logs = True\n",
    "epochs = 1\n",
    "rotate_angle=None\n",
    "horizontal_flip_prob=None\n",
    "brightess_contrast=None\n",
    "gaussian_blur=None\n",
    "normalize=True\n",
    "seed = 42\n",
    "batch_size = 32\n",
    "results_folder_name = \"test\"\n",
    "truncated_layers = 0\n",
    "bootstrap_n = None\n",
    "pretrained = True\n",
    "dropout_p = .2\n",
    "train_prop = .8\n",
    "val_prop = .1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10a38c2f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 4182, Validation size: 522, Test size: 524\n"
     ]
    }
   ],
   "source": [
    "train_transform = data_transformation_pipeline(image_size = image_size,\n",
    "                                               center_crop=center_crop,\n",
    "                                               rotate_angle=rotate_angle,\n",
    "                                               horizontal_flip_prob=horizontal_flip_prob,\n",
    "                                               gaussian_blur=gaussian_blur,\n",
    "                                               normalize=normalize,\n",
    "                                               is_train=True)\n",
    "test_transform = data_transformation_pipeline(image_size = image_size,\n",
    "                                              center_crop=center_crop,\n",
    "                                               rotate_angle=rotate_angle,\n",
    "                                               horizontal_flip_prob=horizontal_flip_prob,\n",
    "                                               gaussian_blur=gaussian_blur,\n",
    "                                               normalize=normalize,\n",
    "                                               is_train=False)\n",
    "val_transform = data_transformation_pipeline(image_size = image_size,\n",
    "                                             center_crop=center_crop, \n",
    "                                               rotate_angle=rotate_angle,\n",
    "                                               horizontal_flip_prob=horizontal_flip_prob,\n",
    "                                               gaussian_blur=gaussian_blur,\n",
    "                                               normalize=normalize,\n",
    "                                               is_train=False)\n",
    "\n",
    "\n",
    "train_loader , val_loader, test_loader, num_classes = data_loader(data_dir, \n",
    "                                                     train_transform=train_transform,\n",
    "                                                     test_transform=test_transform,\n",
    "                                                     val_transform=val_transform,\n",
    "                                                     seed=seed,\n",
    "                                                     batch_size=batch_size,\n",
    "                                                     train_prop=train_prop,\n",
    "                                                     val_prop =val_prop\n",
    "                                                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COVID': 160, 'NORMAL': 182, 'PNEUMONIA': 182}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "# Get class names\n",
    "dataset = ImageFolder(data_dir)  # Load without transformations just to access class names\n",
    "class_names = dataset.classes\n",
    "\n",
    "\n",
    "def count_samples_per_class(dataset, class_names):\n",
    "    \"\"\"Counts the number of samples per class in a dataset split.\"\"\"\n",
    "    class_counts = Counter([dataset.dataset.samples[idx][1] for idx in dataset.indices])\n",
    "    return {class_names[class_idx]: count for class_idx, count in class_counts.items()}\n",
    "\n",
    "count_samples_per_class(test_loader.dataset, class_names)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COVID': 0, 'NORMAL': 1, 'PNEUMONIA': 2}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "def load_model(model_name, **kwargs):\n",
    "    \"\"\"Dynamically loads and instantiates a model from custom_lib.custom_models.\"\"\"\n",
    "    module = importlib.import_module(f\"custom_lib.custom_models.{model_name}\")\n",
    "    \n",
    "    # Find the first class in the module (assuming only one model class per file)\n",
    "    model_class = getattr(module, model_name, None)\n",
    "    \n",
    "    if model_class is None:\n",
    "        raise ValueError(f\"Could not find a class named '{model_name}' in '{module.__name__}'\")\n",
    "\n",
    "    return model_class(**kwargs)\n",
    "\n",
    "\n",
    "model = load_model(\n",
    "    model_name,\n",
    "    num_classes=num_classes,\n",
    "    removed_layers=truncated_layers,\n",
    "    batch_size=batch_size,\n",
    "    image_size=image_size,\n",
    "    pretrained=pretrained,\n",
    "    dropout_p=dropout_p\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_logs:\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "\n",
    "    # Create directory for saving all logs and model outputs \n",
    "    results_dir = os.path.join(f\"{results_folder_name}/{model_name}_reduced_layers_{truncated_layers}_{timestamp}\")\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    print(f\"Logs and output will be saved in: {results_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 6. Wrap the model with Poutyne\n",
    "poutyne_model = Model(\n",
    "    model,\n",
    "    # optimizer=torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9),  # Added momentum\n",
    "\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=lr),\n",
    "    loss_function=nn.CrossEntropyLoss(),\n",
    "    batch_metrics=[\"accuracy\"],\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from poutyne import ReduceLROnPlateau, Callback\n",
    "\n",
    "# Add the ReduceLROnPlateau callback\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    factor=0.1,          # Reduce LR by a factor of 0.1\n",
    "    patience=5           # Wait 5 epochs before reducing LR\n",
    "\n",
    ")\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', patience = 10)\n",
    "\n",
    "class PrintLRSchedulerCallback(Callback):\n",
    "    def set_model(self, model):\n",
    "        self.model = model  # Store the model reference\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        lr = self.model.optimizer.param_groups[0]['lr']\n",
    "        print(f\"Epoch {epoch + 1}: Current LR = {lr}\")\n",
    "\n",
    "# Instantiate the callback\n",
    "print_lr_callback = PrintLRSchedulerCallback()\n",
    "\n",
    "# Add it to the list of callbacks\n",
    "# callbacks = [reduce_lr, early_stopping, print_lr_callback]\n",
    "callbacks = [reduce_lr, print_lr_callback]\n",
    "\n",
    "if save_logs == True:\n",
    "    # Callback: Save the best model based on validation accuracy\n",
    "    checkpoint = ModelCheckpoint(f\"{results_dir}/best_model.pth\", monitor='val_loss', mode='min', save_best_only=True)\n",
    "    csv_logger = CSVLogger(f\"{results_dir}/training_logs.csv\")\n",
    "    callbacks = [checkpoint, csv_logger, reduce_lr, print_lr_callback]\n",
    "    \n",
    "\n",
    "start_time = time.time()\n",
    "# 7. Train the model\n",
    "history = poutyne_model.fit_generator(train_loader, val_loader, epochs=epochs, verbose=True,\n",
    "                            callbacks = callbacks)\n",
    "end_time = time.time()\n",
    "\n",
    "run_time = end_time - start_time\n",
    "\n",
    "print(f\"Model training took {run_time / 60} minutes\")\n",
    "\n",
    "if save_logs:\n",
    "    # Save the final model manually\n",
    "    torch.save(poutyne_model.network.state_dict(), f\"{results_dir}/final_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_logs:\n",
    "    best_model_path = f\"{results_dir}/best_model.pth\"\n",
    "    \n",
    "    # Load the state dict into the model\n",
    "    poutyne_model.network.load_state_dict(torch.load(best_model_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thop import profile\n",
    "\n",
    "# Create a dummy input tensor with the same shape as your model's input\n",
    "dummy_input = torch.randn(batch_size, 3, image_size, image_size).to(device)  # Batch size = 1, Channels = 3, Height = image_size, Width = image_size\n",
    "\n",
    "# Compute FLOPs and parameters\n",
    "flops, params = profile(model, inputs=(dummy_input,))\n",
    "\n",
    "gflops = flops / 1000000000\n",
    "\n",
    "print(f\"GFLOPs: {gflops}\")\n",
    "print(f\"Parameters: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(\n",
    "        history,\n",
    "        metrics=['loss', 'acc'],\n",
    "        labels=['Loss', 'Accuracy'],\n",
    "        titles=f\"{model_name} Training\",\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if bootstrap_n == None:\n",
    "\n",
    "    # Evaluate using Poutyne\n",
    "    test_loss, test_acc = poutyne_model.evaluate_generator(test_loader)\n",
    "else: \n",
    "    from custom_lib.bootstrap import bootstrap_evaluation_poutyne\n",
    "\n",
    "    if save_logs:\n",
    "        # Run bootstrapping evaluation with your Poutyne model\n",
    "        boot_strap_results = bootstrap_evaluation_poutyne(poutyne_model, test_loader, n_bootstraps = bootstrap_n, save_logs=save_logs, results_dir=results_dir, seed=seed)\n",
    "    else:\n",
    "        boot_strap_results = bootstrap_evaluation_poutyne(poutyne_model, test_loader, n_bootstraps = bootstrap_n, save_logs=save_logs, seed=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_loader))[0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save logs and plots\n",
    "if save_logs:\n",
    "    with open(f\"{results_dir}/model_overview.txt\", \"w\") as file:\n",
    "        file.write(f\"Model Structure:\\n{model}\\n\")\n",
    "        file.write(f\"Using {device} device\\n\")\n",
    "\n",
    "# Check if CSV exists\n",
    "    if os.path.exists(f\"{results_folder_name}/test_results.csv\"):\n",
    "        test_results_df = pd.read_csv(f\"{results_folder_name}/test_results.csv\")\n",
    "    else:\n",
    "        test_results_df = pd.DataFrame(columns=[\n",
    "            \"model_id\", \"model\", \"epochs\", \"run_time\", \"lr\", \"image_size\",\n",
    "            \"rotate_angle\", \"horizontal_flip_prob\", \"gaussian_blur\", \"normalize\", \"seed\", \"truncated_layers\"\n",
    "        ])\n",
    "\n",
    "    if bootstrap_n != None:\n",
    "        test_loss = None\n",
    "        test_acc = None\n",
    "\n",
    "\n",
    "    # Create a DataFrame for the new model's metadata\n",
    "    new_results_df = pd.DataFrame({\n",
    "        \"model_id\": [f\"{model_name}_reduced_layers_{truncated_layers}_{timestamp}\"],\n",
    "        \"model\": [model_name],\n",
    "        \"truncated_layers\": [truncated_layers],\n",
    "        \"epochs\": [epochs],  \n",
    "        \"batch_size\": [batch_size],\n",
    "        \"run_time\": [run_time / 60],  \n",
    "        \"lr\": [lr],\n",
    "        \"image_size\": [image_size],  \n",
    "        \"rotate_angle\": [rotate_angle],  \n",
    "        \"horizontal_flip_prob\": [horizontal_flip_prob],  \n",
    "        \"gaussian_blur\": [gaussian_blur],  \n",
    "        \"normalize\": [normalize],\n",
    "        \"seed\": [seed],\n",
    "        \"gflops\": [gflops],\n",
    "        \"params\": [params],\n",
    "        \"single_test_acc\": [test_acc],\n",
    "        \"single_test_loss\": [test_loss],\n",
    "        \"bootstrap_n\": [bootstrap_n]\n",
    "        })\n",
    "\n",
    "    if bootstrap_n != None:\n",
    "        # Combine test metadata with bootstrapped results (column-wise merge)\n",
    "        new_results_df = pd.concat([new_results_df, boot_strap_results], axis=1)\n",
    "\n",
    "\n",
    "    # Append to existing DataFrame\n",
    "    test_results_df = pd.concat([test_results_df, new_results_df], ignore_index=True)\n",
    "\n",
    "    # Save updated results\n",
    "    test_results_df.to_csv(f\"{results_folder_name}/test_results.csv\", index=False)\n",
    "\n",
    "    # Plot training history\n",
    "    plot_history(\n",
    "        history,\n",
    "        metrics=['loss', 'acc'],\n",
    "        labels=['Loss', 'Accuracy'],\n",
    "        titles=f\"{model_name} Training\",\n",
    "        save=True,  \n",
    "        save_filename_template='{metric}_plot',  \n",
    "        save_directory=results_dir,  \n",
    "        save_extensions=('png',)  \n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
